{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Машинное обучение, ВМК МГУ\n",
    "\n",
    "## Практическое задание 2\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 9 октября 2019\n",
    "\n",
    "Максимальная оценка: 10 баллов + 1 бонусный балл\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 23 октября (за каждый день просрочки снимается 1 балл)\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 30 октября."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании вы:\n",
    "- Познакомитесь с методом решения задачи регрессии на основе метода ближайших соседей.\n",
    "- Реализуете алгоритм kNN для задачи регрессии.\n",
    "- Изучите методы работы с категориальными и текстовыми переменными.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл *.ipynb в соответствии со следующим форматом: homework-practice-02-Username.ipynb, где Username — ваша фамилия и имя на латинице именно в таком порядке (например, homework-practice-02-ivanov.ipynb).\n",
    "\n",
    "Далее отправьте этот файл на anytask в соответсвующий раздел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add status bar functionality\n",
    "\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все эксперименты в этой лабораторной работе предлагается проводить на данных соревнования New York City Airbnb Open Data: https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data#AB_NYC_2019.csv\n",
    "\n",
    "В данной задаче предлагается предсказать цену на съем квартиры в зависимости от её параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('AB_NYC_2019.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48895, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 48895\n",
      "name 47906\n",
      "host_id 37457\n",
      "host_name 11453\n",
      "neighbourhood_group 5\n",
      "neighbourhood 221\n",
      "latitude 19048\n",
      "longitude 14718\n",
      "room_type 3\n",
      "price 674\n",
      "minimum_nights 109\n",
      "number_of_reviews 394\n",
      "last_review 1765\n",
      "reviews_per_month 938\n",
      "calculated_host_listings_count 47\n",
      "availability_365 366\n"
     ]
    }
   ],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print(col_name, len(data[col_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                    0\n",
       "name                                 16\n",
       "host_id                               0\n",
       "host_name                            21\n",
       "neighbourhood_group                   0\n",
       "neighbourhood                         0\n",
       "latitude                              0\n",
       "longitude                             0\n",
       "room_type                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "last_review                       10052\n",
       "reviews_per_month                 10052\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, в данных есть пропуски. Не забудьте обработать их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь (ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆\n",
    "numberCols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numberCols.remove('id')\n",
    "numberCols.remove('price')\n",
    "\n",
    "categoricalCols = ['neighbourhood_group', 'neighbourhood', 'room_type']\n",
    "\n",
    "data[numberCols] = data[numberCols].fillna(0)\n",
    "data[categoricalCols] = data[categoricalCols].fillna('')\n",
    "\n",
    "textCols = ['name']\n",
    "data[textCols] = data[textCols].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем данные на обучение и контроль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['price']), data[['price']],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Алгоритм kNN в задаче регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1.1 (1.5 балла) </b>\n",
    "Реализуйте класс `KNNRegressor`, который используя метод k ближайших соседей решает задачу регрессии. Для решение данной задачи, необходимо найти $N_k$ - k соседей, и после использовать значения их целевых переменных для предсказания:\n",
    "\\begin{align}\n",
    "y = \\frac{1}{k}\\sum_{n \\in N_k}w_n y_n,\n",
    "\\end{align}\n",
    "\n",
    "где $w_n$ - вес каждого соседа. \n",
    "\n",
    "При этом `KNNRegressor` может работать в 2 режимах:\n",
    " - $uniform$ - ближайшие соседи учитываются с одинаковыми весами.\n",
    " - $distance$ - вес ближайших соседей зависит от расстояния\n",
    " \n",
    "Сигнатуру методов при желании можно менять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable, Iterable, Optional\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "class KNNRegressor:\n",
    "    def __init__(self, n_neighbors: int, metric: Union[str, Callable], mode: str = 'uniform'):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            n_neighbors: number of neighbors\n",
    "            metric: metric to use for distance computation\n",
    "            mode: 'uniform' or 'distance'\n",
    "            'uniform' - all points in each neighborhood are weighted equally\n",
    "            'distance' - weight points by the inverse of their distance\n",
    "        \"\"\"\n",
    "#         self.__nn = NearestNeighbors(n_neighbors = n_neighbors, metric = metric)\n",
    "#         self.__nnTest = KNeighborsRegressor(n_neighbors = n_neighbors, metric = metric, weights = mode)\n",
    "        self.__metric = metric\n",
    "        self.__mode = mode\n",
    "        self.__n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array) -> None:\n",
    "        \"\"\"\n",
    "            X: data\n",
    "            y: labels\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        self.__X = X\n",
    "        self.__y = y\n",
    "#         self.__nn.fit(X, y)\n",
    "#         self.__nnTest.fit(X, y)\n",
    "        \n",
    "    def euclidean_distance(self, X, Y):\n",
    "        d = len(X[0])\n",
    "        res = np.zeros(len(X)*len(Y)).reshape(len(X), len(Y))\n",
    "        for x in range(len(X)):\n",
    "            for y in range(len(Y)):\n",
    "                sum = 0\n",
    "                for f in range(len(Y[y])):\n",
    "                    sum += (X[x][f] - Y[y][f])**2\n",
    "                res[x][y] = np.sqrt(sum)\n",
    "        return res;\n",
    "\n",
    "    def cosine_distance(self, X, Y):\n",
    "        sumyy = (Y**2).sum(1)\n",
    "        sumxx = (X**2).sum(1, keepdims=1)\n",
    "        sumxy = X.dot(Y.T)\n",
    "        return 1 - (sumxy / np.sqrt(sumxx)) / np.sqrt(sumyy)\n",
    "    \n",
    "    def overlap(self, X, Y):\n",
    "        res = []\n",
    "        res = np.zeros(len(X)*len(Y)).reshape(len(X), len(Y))\n",
    "        for x in range(len(X)):\n",
    "            for y in range(len(Y)):\n",
    "                dist = 0\n",
    "                for f in range(len(Y[y])):\n",
    "                    if (X[x][f] != Y[y][f]):\n",
    "                        dist = 1\n",
    "                        break\n",
    "                res[x][y] = dist\n",
    "        return res;\n",
    "\n",
    "    def flattened_overlap(self, X, Y):\n",
    "        # находим частоту признаков\n",
    "        freqs = {}\n",
    "        for col in range(X.shape[1]):\n",
    "            values, freq = np.unique(X[:,col], return_counts=True)\n",
    "            freqs[col] = {values[q]: freq[q] for q in range(len(values))} \n",
    "        \n",
    "        res = np.zeros(len(X)*len(Y)).reshape(len(X), len(Y))\n",
    "        for x in range(len(X)):\n",
    "            for y in range(len(Y)):\n",
    "                dist = 0\n",
    "                p = 0\n",
    "                for c in range(len(Y[y])):\n",
    "                    if (X[x][c] != Y[y][c]):\n",
    "                        dist = 1\n",
    "                        p = 0\n",
    "                        break\n",
    "                    else:\n",
    "                        dp = (freqs[c][X[x][c]] * (freqs[c][X[x][c]] - 1)) / (len(X) * (len(X) - 1 ))\n",
    "                        p = p + dp\n",
    "                \n",
    "                res[x][y] = dist + p\n",
    "        return res;\n",
    "    \n",
    "    def log_overlap(self, X, Y):\n",
    "        \n",
    "        # находим частоту признаков\n",
    "        freqsX = {}\n",
    "        for col in range(X.shape[1]):\n",
    "            values, freq = np.unique(X[:,col], return_counts=True)\n",
    "            freqsX[col] = {values[q]: freq[q] for q in range(len(values))} \n",
    "\n",
    "        freqsY = {}\n",
    "        for col in range(Y.shape[1]):\n",
    "            values, freq = np.unique(Y[:,col], return_counts=True)\n",
    "            freqsY[col] = {values[q]: freq[q] for q in range(len(values))} \n",
    "        \n",
    "        res = np.zeros(len(X)*len(Y)).reshape(len(X), len(Y))\n",
    "        for x in range(len(X)):\n",
    "            for y in range(len(Y)):\n",
    "                dist = 0\n",
    "                for c in range(len(Y[y])):\n",
    "                    if (X[x][c] != Y[y][c]):\n",
    "                        dist = dist + np.log(1 + freqsX[c][X[x][f]]) * np.log(1 + freqsY[c][Y[x][f]])\n",
    "                \n",
    "                res[x][y] = dist\n",
    "        return res;\n",
    "\n",
    "    def find_kneighbors(self, X, return_distance = True):\n",
    "        \n",
    "        if (self.__metric == 'euclidean'):\n",
    "            dsModRes = self.euclidean_distance(X, self.__X)\n",
    "        elif (self.__metric == 'cosine'):\n",
    "            dsModRes = self.cosine_distance(X, self.__X)\n",
    "        elif (self.__metric == 'overlap'):\n",
    "            dsModRes = self.overlap(X, self.__X)\n",
    "        elif (self.__metric == 'flattened_overlap'):\n",
    "            dsModRes = self.flattened_overlap(X, self.__X)\n",
    "        elif (self.__metric == 'log_overlap'):\n",
    "            dsModRes = self.flattened_overlap(X, self.__X)\n",
    "        else:\n",
    "            raise Exception(\"Unknown 'metric' param value\")\n",
    "\n",
    "        res = []\n",
    "        dists = []\n",
    "        for i in range(len(dsModRes)):\n",
    "            tmpDists = np.argsort(dsModRes[i])[:self.__n_neighbors]\n",
    "            res.append(dsModRes[i][tmpDists])\n",
    "            if (return_distance):\n",
    "                dists.append(tmpDists)\n",
    "\n",
    "        if (return_distance):\n",
    "            return (res, dists)\n",
    "        else:\n",
    "            return (res)\n",
    "        \n",
    "    def predict(self, X: np.array, n_neighbors: Optional[int] = None) -> np.array:\n",
    "        \"\"\"\n",
    "            X: data\n",
    "            n_neighbors: number of neighbors\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "#         distances, indices = self.__nn.kneighbors(X)\n",
    "#         distances, indices = self.__nnTest.kneighbors(X)\n",
    "        distances, indices = self.find_kneighbors(X)\n",
    "    \n",
    "        if (self.__mode == 'uniform'):\n",
    "            res = self.__y[indices].mean(axis=1)\n",
    "        else: \n",
    "            res = []\n",
    "            for row in range(len(indices)):\n",
    "                predictedVal = 0\n",
    "                weightsSum = 0\n",
    "                for col in range(len(indices[row])):\n",
    "                    w = 1 / (1 + distances[row][col])\n",
    "                    weightsSum = weightsSum + w\n",
    "                    predictedVal = predictedVal + w * self.__y[indices[row][col]]\n",
    "                res.append(predictedVal / weightsSum)\n",
    "            res = np.array(res)\n",
    "#         return self.__nnTest.predict(X)\n",
    "        return res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 86.66666667 333.33333333 260.         154.66666667 125.33333333\n",
      "  70.         199.66666667 181.33333333 333.33333333  75.66666667\n",
      " 241.66666667 140.          86.66666667  87.66666667 218.66666667\n",
      "  88.66666667  90.33333333 130.         186.66666667 113.\n",
      " 187.66666667 186.         195.          90.          86.66666667\n",
      " 119.66666667  79.33333333  63.         130.         120.\n",
      " 193.33333333 115.66666667  63.         111.         114.33333333\n",
      " 183.33333333  56.33333333 129.33333333 183.33333333 212.33333333\n",
      " 130.          68.33333333 176.66666667 319.66666667 104.66666667\n",
      " 164.33333333 143.33333333  65.66666667 111.66666667  77.66666667\n",
      " 270.         146.66666667 101.66666667 134.66666667 139.33333333\n",
      " 129.          61.33333333  99.33333333 149.66666667  62.\n",
      "  71.66666667  74.66666667  68.33333333  98.66666667  57.33333333\n",
      " 113.33333333  85.66666667  98.         114.33333333 240.\n",
      " 178.33333333  84.66666667 105.66666667  88.33333333 187.66666667\n",
      " 110.66666667 111.33333333 175.          63.          71.\n",
      " 123.33333333  99.         116.66666667 135.66666667 175.33333333\n",
      "  68.33333333  99.33333333  63.         112.66666667  99.33333333\n",
      "  99.33333333 123.         194.66666667 123.          93.33333333\n",
      " 108.33333333 148.33333333 113.33333333 270.         126.\n",
      " 134.66666667  84.          91.66666667 228.         133.33333333\n",
      " 151.33333333  91.66666667 183.33333333 134.         105.66666667\n",
      "  71.33333333  97.33333333 175.33333333 196.66666667  70.\n",
      " 121.         138.66666667 401.33333333 141.33333333 178.33333333\n",
      "  68.33333333 113.33333333 136.         356.33333333 256.66666667\n",
      " 121.66666667 313.33333333 106.33333333 175.         123.\n",
      " 123.         160.         189.66666667 200.         132.66666667\n",
      " 116.         180.33333333 136.66666667 141.33333333 120.\n",
      " 209.66666667 188.33333333 150.         200.         209.66666667\n",
      "  62.         153.33333333  82.66666667  78.66666667 189.\n",
      " 134.33333333 107.33333333 114.33333333  62.         156.66666667\n",
      "  97.33333333 109.          55.         111.33333333 105.\n",
      " 149.66666667  88.66666667 135.33333333 189.66666667 140.\n",
      " 114.33333333 145.          76.66666667  93.33333333 126.66666667\n",
      " 123.66666667  93.33333333 426.66666667 130.         154.66666667\n",
      " 256.66666667 190.          92.66666667  87.33333333 121.66666667\n",
      " 204.66666667 128.33333333 138.33333333 126.66666667  53.\n",
      " 146.66666667 129.          98.         188.33333333 111.66666667\n",
      " 156.66666667 108.66666667 147.          66.66666667 153.33333333\n",
      " 199.33333333  93.33333333  93.33333333 148.33333333  55.\n",
      "  78.         119.66666667 112.66666667  54.33333333  71.66666667\n",
      " 189.66666667  56.33333333 150.         229.66666667 154.66666667\n",
      " 173.33333333 125.66666667 183.         171.33333333 115.\n",
      "  98.         177.66666667 140.33333333 100.         200.\n",
      " 136.66666667 346.33333333  93.33333333 109.         106.33333333\n",
      " 173.66666667 120.         146.66666667 181.33333333  56.33333333\n",
      " 127.33333333 107.33333333 127.33333333  84.66666667 143.\n",
      " 113.          56.66666667 131.66666667  88.33333333 212.33333333\n",
      " 145.66666667  68.33333333 136.66666667 108.33333333 313.33333333\n",
      "  71.         130.66666667 123.         222.66666667 129.\n",
      "  93.33333333  71.         145.66666667 213.33333333  96.33333333\n",
      " 172.          97.66666667  95.          88.66666667  40.\n",
      " 105.         110.66666667 143.33333333 129.33333333 166.33333333\n",
      " 162.66666667 120.         118.33333333 195.         129.\n",
      " 149.33333333 136.         134.         132.33333333 176.66666667\n",
      " 320.33333333 106.33333333 260.         121.66666667 190.\n",
      " 313.66666667 188.33333333 120.         100.          67.\n",
      "  61.66666667 140.         257.66666667 298.66666667  56.66666667\n",
      " 235.         115.         123.         213.33333333  99.\n",
      "  74.66666667  82.66666667 193.66666667 146.66666667 164.33333333\n",
      " 129.          53.         136.66666667 116.          90.\n",
      " 147.33333333 127.66666667  96.33333333 120.         172.\n",
      " 145.         527.33333333  87.66666667 101.33333333 190.\n",
      "  71.66666667  98.66666667 172.          73.         231.33333333\n",
      " 166.33333333 126.         191.66666667 118.33333333 143.33333333\n",
      " 210.         156.66666667  75.66666667 488.33333333 135.\n",
      " 136.66666667 171.33333333  56.66666667 123.33333333  64.\n",
      " 110.          96.         191.66666667  94.         115.\n",
      " 187.66666667 111.33333333 156.66666667  94.33333333  84.\n",
      " 134.66666667 178.66666667 106.33333333  98.         101.66666667\n",
      " 136.         104.         119.          91.66666667  86.33333333\n",
      "  57.         111.33333333  77.33333333 178.33333333 176.66666667\n",
      " 149.66666667  56.66666667 118.33333333 178.33333333 161.33333333\n",
      " 121.         132.33333333 115.         113.         122.33333333\n",
      "  93.33333333  90.          61.33333333  87.33333333 130.\n",
      " 199.33333333  93.          88.         195.         148.33333333\n",
      " 179.33333333  70.          71.66666667 190.          61.\n",
      " 378.33333333 238.33333333 200.         212.33333333 110.\n",
      " 238.          85.         136.66666667 105.          71.66666667\n",
      " 313.33333333  79.33333333 228.33333333 113.         140.\n",
      " 199.66666667  99.66666667 105.         134.66666667 189.66666667\n",
      " 128.33333333 108.33333333 200.         116.66666667 120.66666667\n",
      " 143.33333333 346.33333333 119.66666667 163.66666667 260.\n",
      " 194.66666667  61.         117.33333333  66.66666667  56.66666667\n",
      " 126.33333333 115.         130.         100.         179.66666667\n",
      " 113.         222.66666667 142.33333333 123.33333333 110.66666667\n",
      "  37.         132.66666667 118.33333333 346.33333333 114.33333333\n",
      " 129.33333333 248.33333333 107.         139.66666667  86.66666667\n",
      " 458.         148.33333333 183.33333333 120.66666667  95.\n",
      " 115.         179.66666667 116.66666667  46.33333333 126.66666667\n",
      " 608.         128.         139.          71.          45.66666667\n",
      " 119.66666667 106.66666667 135.33333333  48.33333333  64.\n",
      "  98.         149.33333333 121.33333333  54.33333333 105.\n",
      " 121.66666667 367.66666667  74.66666667 426.66666667  45.66666667\n",
      " 173.33333333 608.          75.         103.33333333 134.66666667\n",
      " 172.         130.         111.33333333 135.          49.66666667\n",
      " 105.         139.66666667 141.33333333 146.         126.\n",
      " 403.         105.         126.33333333 260.         108.33333333\n",
      " 108.33333333 187.         129.66666667  83.33333333 154.\n",
      "  85.         301.33333333 204.33333333 204.33333333  66.66666667\n",
      " 222.66666667  48.33333333 310.          89.66666667 112.66666667\n",
      "  90.33333333 183.         301.33333333 158.33333333 128.33333333\n",
      " 260.          98.33333333 164.33333333 135.66666667 114.33333333\n",
      " 163.33333333  84.         111.33333333  75.66666667 163.\n",
      "  81.          91.66666667 204.33333333  40.          85.33333333\n",
      " 150.33333333 149.66666667  98.66666667 112.66666667  52.\n",
      " 104.66666667 107.         319.66666667 125.         162.66666667\n",
      " 103.33333333 244.66666667 101.66666667  65.          40.\n",
      " 102.66666667 118.         118.66666667 313.66666667  98.66666667\n",
      " 149.33333333  96.         143.33333333  78.33333333 120.\n",
      " 156.66666667 115.33333333 102.66666667 202.66666667  69.33333333\n",
      "  46.33333333 193.66666667  84.          91.66666667 120.66666667\n",
      " 125.66666667  64.         393.          61.33333333 123.66666667\n",
      " 171.33333333 143.         181.33333333 260.          83.33333333\n",
      " 113.         106.33333333  63.         106.         310.\n",
      "  77.66666667 110.         207.66666667  93.33333333 212.33333333\n",
      " 241.66666667 119.66666667 133.33333333  87.33333333 100.66666667\n",
      " 207.66666667  97.         190.         218.33333333  50.\n",
      "  86.33333333 127.66666667 115.          97.         193.66666667\n",
      " 138.         136.         189.          85.33333333 116.66666667\n",
      " 100.66666667 367.66666667  99.          91.66666667 195.\n",
      " 179.66666667 180.66666667 248.33333333  55.          90.\n",
      " 208.33333333 149.33333333 112.33333333 196.33333333 135.33333333\n",
      " 179.66666667 367.66666667 238.33333333 116.         103.33333333\n",
      " 115.         126.33333333  71.33333333 140.         109.66666667\n",
      " 120.         195.         163.         200.         135.66666667\n",
      "  92.66666667 134.33333333  84.         148.         200.\n",
      " 150.         446.33333333 100.         135.66666667  77.66666667\n",
      " 476.66666667  54.         204.66666667 183.33333333 106.33333333\n",
      " 133.66666667 312.66666667 195.66666667 146.66666667  91.66666667\n",
      " 123.          93.33333333 179.66666667 173.33333333 121.\n",
      " 161.33333333  87.33333333 204.33333333 134.66666667 119.\n",
      "  72.33333333  77.33333333 291.66666667 199.33333333 123.33333333\n",
      " 268.          85.33333333  86.66666667 182.33333333  40.\n",
      "  97.         136.66666667 123.33333333 145.66666667 140.33333333\n",
      " 179.33333333 172.         118.33333333 135.66666667 183.33333333\n",
      " 105.66666667  77.66666667  70.         115.66666667 485.66666667\n",
      " 180.66666667 177.66666667  85.33333333 113.66666667 179.33333333\n",
      " 128.33333333 302.33333333 375.          97.         126.33333333\n",
      " 186.33333333 141.66666667 205.66666667 102.66666667  49.66666667\n",
      "  79.33333333 110.66666667  83.33333333 312.66666667 136.\n",
      "  87.66666667 153.         134.33333333  76.66666667 141.\n",
      "  77.          75.66666667  57.         115.         119.33333333\n",
      " 101.66666667 110.         166.66666667 156.66666667  71.66666667\n",
      "  68.33333333 193.33333333 201.33333333 113.         119.66666667\n",
      " 330.         157.33333333 120.         145.         115.\n",
      " 145.66666667 128.33333333 101.66666667 153.         148.33333333\n",
      " 139.         161.66666667  76.66666667  87.66666667 136.66666667\n",
      " 175.         151.33333333 253.         111.66666667 119.66666667\n",
      " 146.66666667 488.33333333 127.66666667 186.33333333 204.33333333\n",
      "  93.33333333  40.         127.33333333 145.          92.66666667\n",
      " 112.66666667  87.66666667 103.33333333 138.66666667 146.66666667\n",
      " 222.66666667 118.33333333 204.33333333  96.33333333 118.\n",
      " 110.66666667  99.66666667  99.33333333 298.33333333 161.66666667\n",
      " 115.         111.33333333  55.33333333  56.66666667 108.33333333\n",
      " 362.66666667  61.66666667  65.         104.66666667 171.33333333\n",
      " 142.66666667  53.         164.          92.          56.66666667\n",
      "  95.33333333 312.66666667 204.33333333 124.66666667  86.66666667\n",
      " 106.33333333 200.          96.33333333 149.66666667 101.66666667\n",
      "  86.66666667 298.66666667 202.66666667 129.         248.33333333\n",
      "  48.33333333 124.33333333 134.66666667 121.33333333 139.66666667\n",
      "  79.33333333 139.33333333 221.66666667 161.33333333 173.33333333\n",
      " 195.66666667 148.33333333 145.         123.33333333  85.\n",
      " 181.33333333 149.33333333 120.         186.33333333  54.\n",
      "  79.66666667  86.33333333 141.66666667 113.33333333 118.\n",
      " 106.33333333  76.66666667  64.         178.33333333 196.33333333\n",
      " 113.33333333 140.         229.66666667  99.66666667 375.\n",
      " 147.         195.         195.         123.         121.\n",
      " 313.33333333 149.66666667 256.66666667 204.33333333 212.33333333\n",
      " 125.          98.66666667 105.         145.         148.33333333\n",
      " 148.33333333 123.33333333 183.         186.33333333 210.\n",
      "  94.33333333 216.66666667 141.         112.66666667 150.\n",
      " 480.         106.         111.33333333  79.33333333  99.66666667\n",
      " 150.          68.33333333 139.33333333 194.66666667 181.33333333\n",
      " 159.66666667 117.66666667 118.66666667 187.66666667  96.33333333\n",
      " 121.         113.33333333 128.33333333 173.33333333 320.33333333\n",
      " 105.          76.66666667  94.         118.33333333  91.66666667\n",
      " 105.         488.33333333 238.33333333 175.33333333 166.33333333\n",
      " 161.66666667 608.         119.66666667 130.66666667 139.\n",
      "  83.33333333 118.66666667 110.66666667 121.66666667 135.\n",
      " 100.66666667 148.33333333  86.66666667 401.33333333 129.\n",
      " 112.66666667 121.33333333  79.33333333 200.         260.\n",
      " 150.         183.33333333 106.66666667  97.33333333  93.33333333\n",
      "  93.         446.33333333 127.33333333  63.          93.\n",
      " 106.66666667  76.66666667 136.66666667 146.66666667 121.66666667\n",
      " 105.         166.33333333 113.         149.33333333 488.33333333\n",
      "  96.33333333 123.         446.33333333 112.33333333  96.33333333\n",
      " 135.66666667 140.33333333 123.          66.         111.33333333\n",
      " 485.          93.33333333 185.66666667  87.33333333  95.\n",
      " 148.33333333  76.66666667 187.66666667 111.33333333 133.33333333\n",
      " 313.33333333  98.66666667 117.33333333 200.         116.\n",
      " 222.66666667  40.         145.         320.33333333  56.33333333\n",
      " 106.33333333 115.         310.          93.         218.66666667\n",
      " 182.33333333 100.          86.33333333 186.         118.33333333\n",
      " 485.          48.33333333  71.66666667  66.66666667 123.33333333\n",
      " 104.66666667 190.         135.66666667 218.33333333 139.66666667\n",
      "  99.         123.33333333  98.66666667 260.         193.33333333\n",
      "  99.33333333 113.         115.33333333 110.         164.33333333\n",
      " 188.33333333 121.          46.33333333 401.33333333 129.\n",
      "  55.          87.66666667 128.33333333 116.         189.66666667]\n"
     ]
    }
   ],
   "source": [
    "X_train1 = X_train[0:1000][numberCols].to_numpy()\n",
    "X_test1 = X_test[0:1000][numberCols].to_numpy()\n",
    "y_train1 = y_train[0:1000].to_numpy()[:,0]\n",
    "y_test1 = y_test[0:1000].to_numpy()[:,0]\n",
    "\n",
    "knnr = KNNRegressor(n_neighbors = 3, metric = 'euclidean', mode = 'uniform')\n",
    "knnr.fit(X_train1, y_train1)\n",
    "res = knnr.predict(X_test1)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.1 (1 балл)</b>\n",
    "Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на [третьем семинаре](https://github.com/mmp-mmro-team/mmp_mmro_fall_2019/blob/master/lecture-notes/Sem03_knn.pdf). Не забудьте, что KNNRegressor должен уметь работать с этими функциями расстояния. Как вариант, можно реализовать метрики как [user-defined distance](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train[0:1000][categoricalCols].to_numpy()\n",
    "X_test1 = X_test[0:1000][categoricalCols].to_numpy()\n",
    "y_train1 = y_train[0:1000].to_numpy()[:,0]\n",
    "y_test1 = y_test[0:1000].to_numpy()[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.2 (1 балл)</b> Найдите все категориальные признаки в данных. Подсчитайте для каждой из метрик качество на тестовой выборке `X_test` при числе соседей $k = 10$. Качество измеряйте с помощью RMSE.\n",
    "\n",
    "Какая функция расстояния оказалась лучшей? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "k_max = 35\n",
    "metrics_array = ['overlap', 'flattened_overlap', 'log_overlap']\n",
    "res = np.zeros(k_max * len(metrics_array)).reshape(k_max, len(metrics_array))\n",
    "for m in range(len(metrics_array)):\n",
    "    for k in range(0, k_max):\n",
    "        print(\"Metric: %s , k: %d\" % (metrics_array[m], k + 1))\n",
    "        knnr = KNNRegressor(n_neighbors = k + 1, metric = metrics_array[m], mode = 'distance')\n",
    "        knnr.fit(X_train1, y_train1)\n",
    "        pred = knnr.predict(X_test1)\n",
    "        res[k][m] = np.sqrt(mean_squared_error(y_test1, pred))\n",
    "\n",
    "plt.plot(res)\n",
    "plt.legend(metrics_array, loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.3 (1 балл) бонус</b> Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какого удалось достичь уровня качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для overlap оптимальное значение k = 20 (результат 288.5763)\n",
      "Для flattened_overlap оптимальное значение k = 20 (результат 288.8075)\n",
      "Для log_overlap оптимальное значение k = 20 (результат 288.8075)\n"
     ]
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "metrics_array = ['overlap', 'flattened_overlap', 'log_overlap']\n",
    "for m in range(len(metrics_array)):\n",
    "    k = np.argmin(res[:,m])\n",
    "    print(\"Для %s оптимальное значение k = %d (результат %.4f)\" % (metrics_array[m], k, res[k,m]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.4 (2.5 балла)</b> Отойдем ненадолго от задачи регрессии и перейдём к задаче классификации: будем определять, являеться ли квартира дорогой $(target = 1)$ или дешевой $(target = 0)$. Будем считать дорогими квариры, цена которых выше среднего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = (data.price > data.price.mean()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте счетчики, которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, для каждого категориального признака $f_j(x)$ необходимо сделать следующее:\n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "\\begin{align}\n",
    "counts_j(c) = \\sum_{i=1}^l [f_j(x_i) = c]\n",
    "\\end{align}\n",
    "2. Число `successes` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "\\begin{align}\n",
    "successes_j(c) = \\sum_{i=1}^l[f_j(x_i) = c][y_i = +1].\n",
    "\\end{align}\n",
    "3. Сглаженное отношение двух предыдущих величин:\n",
    "\\begin{align}\n",
    "p_j(c) = \\frac{successes_j(c) + a}{counts_j(c) + b},\n",
    "\\end{align}\n",
    "\n",
    "где $a$ и $b$ - априорные счетчики (например, a = 1, b = 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.8,\n",
       " 'b': 0.6666666666666666,\n",
       " 'c': 0.6666666666666666,\n",
       " 'd': 0.75,\n",
       " 'e': 0.6666666666666666,\n",
       " 'f': 0.6666666666666666}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def counters(x):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        x: value on categorical feature for N objects\n",
    "    returns: vector of length N\n",
    "    \"\"\"\n",
    "    # Ваш код здесь\n",
    "    pass\n",
    "\n",
    "def counts(X: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    params:\n",
    "        x: value on categorical feature for N objects\n",
    "    returns: vector of length N\n",
    "    \"\"\"\n",
    "    # Ваш код здесь\n",
    "    res = {}\n",
    "    unique, counts = np.unique(X, return_counts = True)\n",
    "    return dict(np.asarray((unique, counts)).T)\n",
    "\n",
    "def successes(X: np.array, Y: np.array) -> np.array:\n",
    "    res = {}\n",
    "    \n",
    "    unique = np.unique(X, return_counts = False)\n",
    "    for val in unique:\n",
    "        count = 0\n",
    "        for row in range(len(X)):\n",
    "            if ((X[row] == val) and X[row]):\n",
    "                count = count + 1\n",
    "        res[val] = count\n",
    "    \n",
    "    return res\n",
    "\n",
    "def flattened(X: np.array, Y: np.array, a: int = 1, b: int = 2) -> np.array:\n",
    "    cnts = counts(X)\n",
    "    scses = successes(X, Y)\n",
    "   \n",
    "    res = {}\n",
    "    for key in cnts:\n",
    "        res[key] = (int(scses[key]) + a) / (int(cnts[key]) + b)\n",
    "    \n",
    "    return res\n",
    "\n",
    "# counts(['a','b','c','a','e','d','d','f','a'])\n",
    "# successes(['a','b','c','a','e','d','d','f','a'], [1,0,1,1,1,0,0,0,1])\n",
    "flattened(['a','b','c','a','e','d','d','f','a'], [1,0,1,1,1,0,0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `successes` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанный по всей обучающей выборке. Реализуйте и такой вариант. Достаточно взять $n = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'a': 0.75,\n",
       "  'b': 0.6666666666666666,\n",
       "  'c': 0.6666666666666666,\n",
       "  'd': 0.75,\n",
       "  'e': 0.6666666666666666,\n",
       "  'f': 0.5},\n",
       " 1: {'a': 1.3333333333333333,\n",
       "  'b': 0.5,\n",
       "  'c': 0.3333333333333333,\n",
       "  'd': 0.75,\n",
       "  'e': 0.3333333333333333,\n",
       "  'f': 0.75},\n",
       " 2: {'a': 0.4,\n",
       "  'b': 0.6666666666666666,\n",
       "  'c': 1.0,\n",
       "  'd': 0.6666666666666666,\n",
       "  'e': 1.0,\n",
       "  'f': 0.75}}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kfold(n, n_folds):\n",
    "    partSize = n // n_folds\n",
    "    indexes = [i for i in range(n)]\n",
    "    np.random.shuffle(indexes)\n",
    "    \n",
    "    res = []\n",
    "    for i in range(n_folds):\n",
    "        test = indexes[partSize*i:partSize*(i+1)]\n",
    "        valid = indexes[0:partSize*i] + indexes[partSize*(i+1):]\n",
    "        res.append((test, valid))\n",
    "\n",
    "    return res\n",
    "\n",
    "def kcounts(X: np.array, n: int) -> np.array:\n",
    "    res = {}\n",
    "    \n",
    "    folds = kfold(len(X), 3)\n",
    "    for fold_index in range(len(folds)):\n",
    "        foldValues = []\n",
    "        for index in folds[fold_index][1]:\n",
    "            foldValues.append(X[index])\n",
    "        cnts = counts(foldValues)\n",
    "        fld = {}\n",
    "        for index in np.unique(X, return_counts = False):\n",
    "            if (index in cnts.keys()):\n",
    "                fld[index] = int(cnts[index])\n",
    "            else:\n",
    "                \"\"\"\n",
    "                если ключь не найден, присваеваем значение 0\n",
    "                это не правильно; в продакшене нужно переделать на NaN с последующей\n",
    "                заменой всех NaN на среднее значение по ключу\n",
    "                \"\"\"\n",
    "                fld[index] = 0\n",
    "        res[fold_index] = fld\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def ksuccesses(X: np.array, Y: np.array, n: int) -> np.array:\n",
    "    res = {}\n",
    "    \n",
    "    folds = kfold(len(X), 3)\n",
    "    for fold_index in range(len(folds)):\n",
    "        foldValues = []\n",
    "        foldAnswers = []\n",
    "        for index in folds[fold_index][1]:\n",
    "            foldValues.append(X[index])\n",
    "            foldAnswers.append(Y[index])\n",
    "        scses = successes(foldValues, foldAnswers)\n",
    "        fld = {}\n",
    "        for index in np.unique(X, return_counts = False):\n",
    "            if (index in scses.keys()):\n",
    "                fld[index] = int(scses[index])\n",
    "            else:\n",
    "                \"\"\"\n",
    "                если ключь не найден, присваеваем значение 0\n",
    "                это не правильно; в продакшене нужно переделать на NaN с последующей\n",
    "                заменой всех NaN на среднее значение по ключу\n",
    "                \"\"\"\n",
    "                fld[index] = 0\n",
    "        res[fold_index] = fld\n",
    "    \n",
    "    return res\n",
    "\n",
    "def kflattened(X: np.array, Y: np.array, n:int, a: int = 1, b: int = 2) -> np.array:\n",
    "    cnts = kcounts(X, n)\n",
    "    scses = ksuccesses(X, Y, n)\n",
    "   \n",
    "    res = {}\n",
    "    for nfold in range(n):\n",
    "        fld = {}\n",
    "        for key in cnts[nfold]:\n",
    "             fld[key] = (int(scses[nfold][key]) + a) / (int(cnts[nfold][key]) + b)\n",
    "        res[nfold] = fld\n",
    "    \n",
    "    return res\n",
    "\n",
    "def fold_counters(x):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        x: value on categorical feature for N objects\n",
    "    returns: vector of length N\n",
    "    \"\"\"\n",
    "    # Ваш код здесь\n",
    "    pass\n",
    "\n",
    "# kcounts(['a','b','c','a','e','d','d','f','a','f'], 3)\n",
    "# ksuccesses(['a','b','c','a','e','d','d','f','a','f'], [1,0,1,1,1,0,0,0,1,0], 3)\n",
    "kflattened(['a','b','c','a','e','d','d','f','a','f'], [1,0,1,1,1,0,0,0,1,0], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.5 (1 балл)</b> Вернемся к задаче регрессии. Утверждается, что для задачи регрессии можно также сделать преобразование категориальных признаков в действительные числа. Для этого достаточно для каждого значения признака $f_j$ вычислить:\n",
    "\\begin{align}\n",
    "p_j(c) = g(T_i | f_j(x_i) = c),\n",
    "\\end{align}\n",
    "\n",
    "где $T_i$ - значения целевой переменной объекта $x_i$. Функция $g$ - среднее (mean) или среднеквадратичное отклонение (std).\n",
    "\n",
    "Закодируйте категориальные признаки обоими способами и найдите значение RMSE. Используйте евклидову метрику для поиска ближайших соседей. Для какой функции $g$ значение RMSE лучше? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Текстовые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.1 (2 балла)</b> Перейдем от категориальным признаков к текстовым. Рассмотрим 2 способа преобразования текста в действительные числа:\n",
    "- Мешок слов (Bag of Words)\n",
    "- TF-IDF\n",
    "\n",
    "[Здесь](https://scikit-learn.org/stable/modules/feature_extraction.html) вы можете прочитать про их применение в Питоне.\n",
    "\n",
    "Сравните оба способа на задаче регресси. Какую лучше метрику использовать: евклидову или косинусную меру? Постройте графики зависимости качества решения задачи от способа преобразования, метрики и количества соседей. Мера качества - RMSE.\n",
    "\n",
    "Объясните полученные результаты.\n",
    "\n",
    "Перед преобразованием не забудьте уменьшить размер словаря. Например, это можно сделать за счет приведения всех слов к одному регистру и удаления [стопслов](https://en.wikipedia.org/wiki/Stop_words) (артиклей, предлогов, союзов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# добавим колонку с текстыми данными\n",
    "X_train['text'] = X_train[['name', 'host_name']].apply(lambda row: ' - '.join(str(colval) for colval in row), axis=1)\n",
    "X_train['text'].str.lower()\n",
    "\n",
    "X_test['text'] = X_test[['name', 'host_name']].apply(lambda row: ' - '.join(str(colval) for colval in row), axis=1)\n",
    "X_test['text'].str.lower()\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "X_train1 = X_train['text'].to_numpy()\n",
    "X_test1 = X_test['text'].to_numpy()\n",
    "y_train1 = y_train.to_numpy()[:,0]\n",
    "y_test1 = y_test.to_numpy()[:,0]\n",
    "\n",
    "vectorizer_train = vectorizer.fit_transform(X_train1)\n",
    "vectorizer_test = vectorizer.transform(X_test1)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(vectorizer_train)\n",
    "X_test_tfidf = tfidf_transformer.transform(vectorizer_test)\n",
    "\n",
    "k_max = 100\n",
    "metrics_array = ['euclidean', 'cosine']\n",
    "res_matrix_length = k_max * len(metrics_array) * 2\n",
    "res = np.zeros(res_matrix_length).reshape(k_max, len(metrics_array) * 2)\n",
    "process_bar_length = res_matrix_length\n",
    "cur_bar_position = 0\n",
    "for t in range(len(['count', 'tfidf'])):\n",
    "    for m in range(len(metrics_array)):\n",
    "        for k in range(0, k_max):\n",
    "            update_progress(cur_bar_position / res_matrix_length)\n",
    "            knnr = KNeighborsRegressor(n_neighbors = k + 1, metric = metrics_array[m], weights = 'distance')\n",
    "            if (t):\n",
    "                knnr.fit(X_train_tfidf, y_train1)\n",
    "                pred = knnr.predict(X_test_tfidf)\n",
    "            else:\n",
    "                knnr.fit(vectorizer_train, y_train1)\n",
    "                pred = knnr.predict(vectorizer_test)\n",
    "            res[k][(t * len(metrics_array)) + m] = np.sqrt(mean_squared_error(y_test1, pred))\n",
    "            cur_bar_position = cur_bar_position + 1\n",
    "    plt.plot(res)\n",
    "\n",
    "plt.plot(res)\n",
    "plt.legend(['euclidean count', 'cosine count', 'euclidean tfidf', 'cosine tfidf'], loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.2 (1 балл)</b> Используя все доступные признаки, решите задачу регрессии. Для категориальных и текстовых признаков выберите лучшие преобразования. Повлияло ли добавление количественного признака на метрику качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "\n",
    "# TODO: test OneHotEncoding\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "X_train['neighbourhood_group_encoded'] = labelencoder.fit_transform(X_train['neighbourhood_group'])\n",
    "X_train['neighbourhood_encoded'] = labelencoder.fit_transform(X_train['neighbourhood'])\n",
    "X_train['room_type_encoded'] = labelencoder.fit_transform(X_train['room_type'])\n",
    "\n",
    "X_test['neighbourhood_group_encoded'] = labelencoder.fit_transform(X_test['neighbourhood_group'])\n",
    "X_test['neighbourhood_encoded'] = labelencoder.fit_transform(X_test['neighbourhood'])\n",
    "X_test['room_type_encoded'] = labelencoder.fit_transform(X_test['room_type'])\n",
    "\n",
    "vectorizer_train = sp.sparse.hstack( \\\n",
    "    (vectorizer.fit_transform(X_train['text']), \\\n",
    "     X_train[numberCols + ['neighbourhood_group_encoded', 'neighbourhood_encoded', 'room_type_encoded']].values, \\\n",
    "    ), format='csr' \\\n",
    ")\n",
    "\n",
    "vectorizer_test = sp.sparse.hstack( \\\n",
    "    (vectorizer.transform(X_test['text']), \\\n",
    "     X_test[numberCols + ['neighbourhood_group_encoded', 'neighbourhood_encoded', 'room_type_encoded']].values, \\\n",
    "    ), format='csr' \\\n",
    ")\n",
    "\n",
    "k_max = 65\n",
    "metrics_array = ['euclidean', 'cosine']\n",
    "res = np.zeros(k_max * len(metrics_array)).reshape(k_max, len(metrics_array))\n",
    "for m in range(len(metrics_array)):\n",
    "    for k in range(0, k_max):\n",
    "        knnr = KNeighborsRegressor(n_neighbors = k + 1, metric = metrics_array[m], weights = 'distance')\n",
    "        knnr.fit(vectorizer_train, y_train)\n",
    "        pred = knnr.predict(vectorizer_test)\n",
    "        res[k][m] = np.sqrt(mean_squared_error(y_test, pred))\n",
    "\n",
    "plt.plot(res)\n",
    "plt.legend(metrics_array, loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219.98738226816715"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4: Выводы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваши выводы здесь (ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
