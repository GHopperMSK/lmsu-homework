{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Машинное обучение, ВМК МГУ\n",
    "\n",
    "## Практическое задание 2\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 9 октября 2019\n",
    "\n",
    "Максимальная оценка: 10 баллов + 1 бонусный балл\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 23 октября (за каждый день просрочки снимается 1 балл)\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 30 октября."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании вы:\n",
    "- Познакомитесь с методом решения задачи регрессии на основе метода ближайших соседей.\n",
    "- Реализуете алгоритм kNN для задачи регрессии.\n",
    "- Изучите методы работы с категориальными и текстовыми переменными.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл *.ipynb в соответствии со следующим форматом: homework-practice-02-Username.ipynb, где Username — ваша фамилия и имя на латинице именно в таком порядке (например, homework-practice-02-ivanov.ipynb).\n",
    "\n",
    "Далее отправьте этот файл на anytask в соответсвующий раздел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все эксперименты в этой лабораторной работе предлагается проводить на данных соревнования New York City Airbnb Open Data: https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data#AB_NYC_2019.csv\n",
    "\n",
    "В данной задаче предлагается предсказать цену на съем квартиры в зависимости от её параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('AB_NYC_2019.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48895, 16)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 48895\n",
      "name 47906\n",
      "host_id 37457\n",
      "host_name 11453\n",
      "neighbourhood_group 5\n",
      "neighbourhood 221\n",
      "latitude 19048\n",
      "longitude 14718\n",
      "room_type 3\n",
      "price 674\n",
      "minimum_nights 109\n",
      "number_of_reviews 394\n",
      "last_review 1765\n",
      "reviews_per_month 938\n",
      "calculated_host_listings_count 47\n",
      "availability_365 366\n"
     ]
    }
   ],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print(col_name, len(data[col_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                    0\n",
       "name                                 16\n",
       "host_id                               0\n",
       "host_name                            21\n",
       "neighbourhood_group                   0\n",
       "neighbourhood                         0\n",
       "latitude                              0\n",
       "longitude                             0\n",
       "room_type                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "last_review                       10052\n",
       "reviews_per_month                 10052\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, в данных есть пропуски. Не забудьте обработать их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь (ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆\n",
    "numberCols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numberCols.remove('id')\n",
    "numberCols.remove('price')\n",
    "\n",
    "categoricalCols = data.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "data[numberCols] = data[numberCols].fillna(0)\n",
    "data[categoricalCols] = data[categoricalCols].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем данные на обучение и контроль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['price']), data[['price']],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Алгоритм kNN в задаче регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1.1 (1.5 балла) </b>\n",
    "Реализуйте класс `KNNRegressor`, который используя метод k ближайших соседей решает задачу регрессии. Для решение данной задачи, необходимо найти $N_k$ - k соседей, и после использовать значения их целевых переменных для предсказания:\n",
    "\\begin{align}\n",
    "y = \\frac{1}{k}\\sum_{n \\in N_k}w_n y_n,\n",
    "\\end{align}\n",
    "\n",
    "где $w_n$ - вес каждого соседа. \n",
    "\n",
    "При этом `KNNRegressor` может работать в 2 режимах:\n",
    " - $uniform$ - ближайшие соседи учитываются с одинаковыми весами.\n",
    " - $distance$ - вес ближайших соседей зависит от расстояния\n",
    " \n",
    "Сигнатуру методов при желании можно менять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable, Iterable, Optional\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "class KNNRegressor:\n",
    "    def __init__(self, n_neighbors: int, metric: Union[str, Callable], mode: str = 'uniform'):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            n_neighbors: number of neighbors\n",
    "            metric: metric to use for distance computation\n",
    "            mode: 'uniform' or 'distance'\n",
    "            'uniform' - all points in each neighborhood are weighted equally\n",
    "            'distance' - weight points by the inverse of their distance\n",
    "        \"\"\"\n",
    "#         self.__nn = NearestNeighbors(n_neighbors = n_neighbors, metric = metric)\n",
    "#         self.__nnTest = KNeighborsRegressor(n_neighbors = n_neighbors, metric = metric, weights = mode)\n",
    "        self.__metric = metric\n",
    "        self.__mode = mode\n",
    "        self.__n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array) -> None:\n",
    "        \"\"\"\n",
    "            X: data\n",
    "            y: labels\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        self.__X = X\n",
    "        self.__y = y\n",
    "        \n",
    "#         self.__nn.fit(X, y)\n",
    "#         self.__nnTest.fit(X, y)\n",
    "        \n",
    "    def euclidean_distance(self, X, Y):\n",
    "        d = len(X[0])\n",
    "        res = np.zeros(len(X)*len(Y)).reshape(len(X), len(Y))\n",
    "        for x in range(len(X)):\n",
    "            for y in range(len(Y)):\n",
    "                sum = 0\n",
    "                for f in range(len(Y[y])):\n",
    "                    sum += (X[x][f] - Y[y][f])**2\n",
    "                res[x][y] = np.sqrt(sum)\n",
    "        return res;\n",
    "\n",
    "    def cosine_distance(self, X, Y):\n",
    "        sumyy = (Y**2).sum(1)\n",
    "        sumxx = (X**2).sum(1, keepdims=1)\n",
    "        sumxy = X.dot(Y.T)\n",
    "        return 1 - (sumxy/np.sqrt(sumxx))/np.sqrt(sumyy)\n",
    "    \n",
    "    def overlap(self, X, Y):\n",
    "        res = []\n",
    "        for row in range(len(X)):\n",
    "            distRow = []\n",
    "            for col in range(len(X[row])):\n",
    "                if (X[row][col] == Y[row][col]):\n",
    "                    distRow.append(0)\n",
    "                else:\n",
    "                    distRow.append(1)\n",
    "            res.append(distRow)\n",
    "        return np.array(res)\n",
    "    \n",
    "    def find_kneighbors(self, X, return_distance = True):\n",
    "        res = []\n",
    "        dists = []\n",
    "        \n",
    "        if (self.__metric == 'euclidean'):\n",
    "            dsModRes = self.euclidean_distance(X, self.__X)\n",
    "        elif (self.__metric == 'cosine'):\n",
    "            dsModRes = self.cosine_distance(X, self.__X)\n",
    "        elif (self.__metric == 'overlap'):\n",
    "            dsModRes = self.overlap(X, self.__X)\n",
    "        else:\n",
    "            raise Exception(\"Unknown 'metric' param value\")\n",
    "\n",
    "        for i in range(len(dsModRes)):\n",
    "            tmpDists = np.argsort(dsModRes[i])[:self.__n_neighbors]\n",
    "            res.append(dsModRes[i][tmpDists])\n",
    "            if (return_distance):\n",
    "                dists.append(tmpDists)\n",
    "\n",
    "        if (return_distance):\n",
    "            return (res, dists)\n",
    "        else:\n",
    "            return (res)\n",
    "        \n",
    "    def predict(self, X: np.array, n_neighbors: Optional[int] = None) -> np.array:\n",
    "        \"\"\"\n",
    "            X: data\n",
    "            n_neighbors: number of neighbors\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "#         distances, indices = self.__nn.kneighbors(X)\n",
    "#         distances, indices = self.__nnTest.kneighbors(X)\n",
    "        distances, indices = self.find_kneighbors(X)\n",
    "\n",
    "        if (self.__mode == 'uniform'):\n",
    "            res = self.__y[indices].mean(axis=1)\n",
    "        else: \n",
    "            res = []\n",
    "            for row in range(len(indices)):\n",
    "                predictedVal = 0\n",
    "                weightsSum = 0\n",
    "                for col in range(len(indices[row])):\n",
    "                    w = 1 / distances[row][col]\n",
    "                    weightsSum = weightsSum + w\n",
    "                    predictedVal = predictedVal + w * self.__y[indices[row][col]]\n",
    "                res.append(predictedVal / weightsSum)\n",
    "            res = np.array(res)\n",
    "#         return self.__nnTest.predict(X)\n",
    "        return res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 90.29251629 397.87046594 353.79719069 159.72786592 143.31365627\n",
      "  72.736916   127.40247415 162.76308321 341.17736679  79.71418919\n",
      " 340.10600726  94.72574994  90.89636432  67.26622542 109.75617273\n",
      "  90.01230259  81.24088082 123.59205132 198.3509165   86.19272515\n",
      " 219.15969862  96.54049984 234.52202703 108.81511737  81.90794333\n",
      " 115.42292938  52.41721869  61.1710198  106.96531463 120.78855289\n",
      " 257.64086499 103.13875653  52.10170039  78.33080373  92.5181504\n",
      " 271.00148252  53.0881226   98.25416924 154.13598334 272.39533882\n",
      "  85.16307246  67.55956254  97.286871   293.88664741  99.72745368\n",
      " 144.85030814 180.89048855  66.06239047 102.51315268  72.5035415\n",
      " 498.4179091  150.32369323 105.39241672 156.63943436 155.2386555\n",
      " 124.65423332  61.2169752  108.08578947 150.05476286  58.99330874\n",
      "  65.27604551  43.14825494  50.84214045 122.02300734  68.99662844\n",
      " 105.67330905  87.64381876  90.57881448 100.62983982 228.78632221\n",
      " 139.90224706  64.98356114  86.75824543  83.5168715  220.71820173\n",
      " 142.15932238 111.38562804 124.18997626  59.39259318  54.34654049\n",
      " 126.34023186  95.13824654 120.7512006  189.9995278  176.59268687\n",
      "  71.18400518 100.24851377  61.61593151 123.07949947 100.30060657\n",
      " 101.66645099 144.21476284 218.2686257  108.19232685  82.36925806\n",
      "  85.92378319 145.95271474  67.06438928 363.23461455 159.01200608\n",
      " 128.54836466  31.75329246  89.27871032 250.84017254 112.60417968\n",
      " 114.88104297  73.81830183 222.70090122 150.68764594  85.03937812\n",
      "  86.05412986  79.81627043 178.29264847 238.79236402  58.99019341\n",
      " 114.47271273 148.84780207 385.48471673 150.39128324 194.23484293\n",
      "  52.81633263  57.77161898 136.37529875 328.25583576 534.16489416\n",
      " 123.29678135 234.27857214 128.34005628  96.8902374  124.3294785\n",
      " 130.18368454 140.44188616 166.65456318 199.34655032 148.50950379\n",
      "  95.36743831 122.00373519 150.56861776 140.49915561 120.54601771\n",
      " 110.64161706 199.8676046  117.34040577 157.99892869 222.54090395\n",
      "  58.99373189  72.80298461  67.81589534  78.00549693 226.85679104\n",
      " 139.06058542 142.99827014 103.33800617  57.99417426  80.98138703\n",
      "  47.78294264 144.84664538  56.09001691 111.46801934 113.31550267\n",
      " 155.36114332  70.85727419 150.18868676 165.47913909 110.8151825\n",
      "  77.63958225 103.08928654  74.02681492  69.86828639 125.41382288\n",
      " 113.50431824  66.52630001 468.14874785 134.78691261 141.05513605\n",
      " 206.81630224 158.28533042 126.00387435  64.84962677 140.04179473\n",
      " 190.12205483  81.82283419 122.60066867 115.73906802  54.04451252\n",
      " 180.04084266  95.01539282  52.44950675 249.63659548 110.56376976\n",
      " 193.93955331 115.03717232  73.33036061  51.20021763 159.87561945\n",
      " 200.93750031  98.33272493  34.29413875 161.44093956  57.00684297\n",
      "  82.74778551 193.20508683 111.147974    51.65179594  46.25769811\n",
      " 158.43775694  53.69240726 111.50506803 245.51837009 172.10904305\n",
      " 169.55105803 165.57731674 150.49784108 158.13508497 102.24071458\n",
      "  82.10118119 183.33354818 130.18828399  77.22471018 237.32452234\n",
      " 172.4919257  367.69837417  92.42570993 113.79552521 101.50163561\n",
      " 113.08473149  68.41662521 194.95523429 158.20282203  74.05931083\n",
      " 154.57469075 112.42525218 145.78338918  50.05153147 144.35452018\n",
      " 146.29833696  43.43116193 119.75593178  93.43356221 142.16246774\n",
      " 249.3596362   64.3236181  169.30712099 114.27695712 399.5087245\n",
      "  74.78817355 132.20698171 125.90793766 150.19650496 116.05760607\n",
      " 105.16748236  55.20355728 117.61417669 259.76245661  98.24102621\n",
      " 394.96919253 106.87295512 107.36915909  53.07851629  36.44842315\n",
      " 100.12475465 100.70110478 142.38011941  82.25518783 119.36084356\n",
      " 184.30078116 135.24882233 124.1959076  207.06873427 156.26413148\n",
      " 214.42570102 187.68111136 168.11002353 102.51368895 235.11512877\n",
      " 312.89772442 105.71002416 225.24887095 175.68753543  93.90980984\n",
      " 331.32729954 148.98666534 121.24896701 139.54434564  63.44066052\n",
      "  64.33802027 122.73335377 276.0745151  243.09807651  56.31992828\n",
      "  77.89221682 133.82029503 124.54835449 100.00601554  92.81702496\n",
      "  60.97373192  87.93421988 184.94186035 154.73806052 147.91048227\n",
      " 129.04995792  53.78430164  97.68376987 118.07620188 112.33940947\n",
      " 195.14854056  73.8124648   95.88348022 123.54673428 108.80444559\n",
      " 158.91443329 698.73665034  97.75841443 101.70644499 316.91357326\n",
      "  72.42969161  54.44255686 134.14251159  64.63704448  83.74858739\n",
      " 126.40442072 219.1800972  225.41818216 115.58212967 131.12736694\n",
      " 191.2353406  116.54084384  74.10480382 455.69629131 155.87059259\n",
      " 115.64159394 157.08264043  57.23883011 105.38816864  78.01446915\n",
      "  77.18506251  99.06162176 212.43821598 125.99786588 103.20556498\n",
      " 149.20268072  78.19844705 190.10840462 109.87144032 110.14630401\n",
      " 187.55475746 183.51624577 125.60675727  65.97823586 123.32204227\n",
      " 137.83974741  38.8280915  136.51054823  82.6919342   81.79580884\n",
      "  58.08157016  85.17553892  47.13699357 120.52453894 218.24818751\n",
      " 233.9890785   62.08720046 118.05774717 185.40744373  86.24602852\n",
      " 114.06175732  56.86967694 102.84391754  97.18138379 118.83128815\n",
      "  71.37543649  73.81241969  61.51253528  82.41922992 133.86319515\n",
      " 201.78805844  97.54860603  95.3959414  233.80475904 119.67280215\n",
      " 149.76264179  69.78079803  70.31639453 362.52650797  65.99058712\n",
      " 307.26172138 241.96684582 205.8243468  232.74497305  83.4611941\n",
      " 193.67464436  88.28370687 154.31532814 107.234291    80.379568\n",
      " 626.14714459  74.98353473 206.26524124 168.46935914 117.66437072\n",
      " 151.51342216  93.25766735 106.59710016 153.26542515 150.05278305\n",
      " 132.73294024 136.6190821  222.94863362 112.18037085 117.95737209\n",
      " 110.3545931  383.91871847 142.21670173 155.8373042  426.17030407\n",
      " 219.59930479  68.24999585 135.00173384  66.85970458  48.20114676\n",
      " 128.93089013 124.8138838  139.49696993  78.6682957  126.82902653\n",
      " 197.14013791 220.99548847 138.172376   162.59501801 102.35006996\n",
      "  37.00000009  94.33573286 151.4242188  368.85266828 104.59124782\n",
      " 219.99081553 398.36806958 105.53504561 163.68717019  91.65257519\n",
      " 650.69999478 120.92303252  94.90240731 114.74939979  95.03978236\n",
      " 118.91606872 140.88814525 122.95024468  46.50657576 116.72017228\n",
      " 487.57645747 103.17152145 201.20583966  73.51628213  47.16899371\n",
      " 108.43830111 115.36636144 106.72021523  40.28083451  75.31038569\n",
      "  60.00666198 147.78958983 123.93183768  59.48338022 120.02601838\n",
      " 126.07945947 313.9283447   82.45991669 184.20565438  48.05350656\n",
      " 155.89112303 573.11508389  69.7562395  105.16540293 113.7580101\n",
      " 147.74165482 145.17407595 111.18691288 207.8572571   49.12652573\n",
      " 121.1114376  129.09250308 138.37956667 143.32848975 133.55774582\n",
      " 404.98384799 122.59966294 126.33309015 263.0459115  116.57828984\n",
      " 114.74186875 164.52704534 136.38114345  89.6336936  173.22155328\n",
      "  82.96851335 283.2237893  204.81499845 236.07292238  69.27961829\n",
      " 222.57290885  20.0003487  223.32431205  94.18274919 117.5306891\n",
      "  60.67188298 183.34628324 289.88540452 178.95058038 110.51938736\n",
      " 312.95500413 100.94288586 141.86139146 154.2772149  100.32491843\n",
      " 147.37528197  58.99534587 111.1856092   77.0393705  172.90816655\n",
      "  89.4729177   86.03021013 221.27890667  35.67055232  85.89564649\n",
      " 156.01870115 221.17512444 113.40529281  96.08615266  49.6218191\n",
      "  60.9000018  109.18416143 290.92629769 123.15325207 217.05980603\n",
      " 104.55198521 308.95926094 141.18455375  71.90894923  35.77525939\n",
      " 142.14322478 119.27025105 142.1969052  332.41113434  76.63997418\n",
      " 135.23286283  97.83838692 134.22534082  72.89626592 121.57438494\n",
      "  86.65498839  95.08806247  84.59598274 194.35920712  70.40191524\n",
      "  57.03130363 202.91677529  60.31566971  87.96902589 122.08622704\n",
      "  58.79321578  83.1532527  461.24941386  61.21697508 111.66745183\n",
      " 193.97701241 144.35452016 195.75628052 294.85784583  81.87430124\n",
      " 177.25595688  83.10345729  77.46316471 123.13237419 146.67528291\n",
      "  72.7995751  105.7998644  164.00430895  76.71540508 185.70952949\n",
      " 316.4180393  153.70475733 151.55482905 120.0750815  117.14834855\n",
      " 152.5200983  124.21267701 192.06118858 211.23142681  50.\n",
      "  98.53371494  73.81512203  99.46009472 108.67459866 207.9015764\n",
      " 114.6101034  185.64126349 215.16829454  85.9548962  116.12902047\n",
      " 119.37833466 342.28401341  92.55408644  85.60131088 234.41134036\n",
      " 181.34364125 176.03703597 399.12601462  61.29969299  83.23605115\n",
      " 217.12398526 188.63285182 147.13931581 193.59327686  81.45906673\n",
      " 102.81246802 352.90744485 241.72107413 120.31725407 100.49361024\n",
      " 120.48511849 135.09356293  81.31557808 144.94992852 120.14900409\n",
      " 112.42590751 234.48143326 173.0786956  108.95722371 108.19140507\n",
      " 149.60555332 142.24555233  55.27909592 136.88462285 202.46999073\n",
      " 198.19363473 202.6685747  113.35152257 138.57738768  59.49738154\n",
      " 270.79441694  54.31707261 163.39367705 259.97922819  71.74405291\n",
      " 147.31365142 264.1950277  226.77739485 192.38398822  72.63755779\n",
      " 120.55800036  78.01271123 290.06919825  95.31952469 159.94109235\n",
      "  95.09431411  35.01011672 229.38405913 178.03556967 144.96404809\n",
      "  91.54603207  64.18846864 238.17046119 207.87648707 148.39784908\n",
      " 271.26951764  85.71820355  89.53441643 182.40431253  35.00383267\n",
      " 121.70761137 155.21492786 147.48183308 256.32096358 102.14796991\n",
      " 211.41434056 169.17530524 158.99372912 136.30520391 232.59943911\n",
      "  92.17619141  79.23424815  78.24215049  94.10926726 549.60391662\n",
      " 155.36555027 190.72286784  85.65702093 112.97331872 197.24543505\n",
      " 155.40110867 291.4391881  438.85534089  98.0560177  124.85777178\n",
      " 192.22580135 122.43082324 173.25329783 107.48804033  57.87817806\n",
      "  64.42310394 100.39866595  60.48704608 249.11384753 182.35982042\n",
      "  64.37029511  94.98893412 136.77819295  83.83577194 139.5992447\n",
      "  65.91039277  73.85190899  58.32579672 120.07813359 155.17586351\n",
      " 134.71348079 103.94749876 189.32351938 139.85292892  72.93952574\n",
      "  71.20717166 226.4682364  183.5487358  115.93243755  93.40887614\n",
      " 357.53365215 202.10164864 120.74840727 166.64129113 116.33892405\n",
      " 288.03352089 136.47855387 132.66034428 138.64268448 163.48511072\n",
      " 232.97783439 181.55288444  94.80426768  84.03541418 140.61327899\n",
      "  93.43362631 117.35311713 192.43591748 113.96851518 189.61662201\n",
      " 190.29336302 443.73524417 109.26391434 202.78201782 173.73019614\n",
      "  75.81255559  37.85636106 135.35214854 111.10495437  89.16870135\n",
      " 102.19679326  80.49509566 110.34154231 161.40981865 150.66095271\n",
      " 222.13811637 109.94011008 124.08193312 105.76649543 119.34661035\n",
      " 113.13748752  90.99206714 101.28374585 336.72277728 179.27500973\n",
      " 106.38102908 120.67187954  52.83919224  65.27404068 133.1027333\n",
      " 174.6036365   55.95965643  70.5943171   60.8998594  198.40224074\n",
      " 111.53763809  53.48275944 169.55919024 140.7784759   44.39480677\n",
      " 110.05859233 267.15080213 234.57394734 127.82680657  90.29251662\n",
      "  76.68685663 199.36567952  71.84496117 148.41241175 105.38027673\n",
      "  88.34517158 178.72839967 194.09546339 135.96501122 244.41262209\n",
      "  63.79073146 108.71677045 153.35386894 119.85052613 157.09045122\n",
      "  94.64632628 155.11837141 167.17452561  84.86968113 149.05743583\n",
      " 215.19228067 158.39392042 143.14908392 182.67153946  81.51007031\n",
      " 158.24769863 108.59981817 123.44116932 159.02007677  57.49564174\n",
      "  86.82740791  91.02831452 127.04396838 119.37389625  77.65235343\n",
      "  86.29427624  43.63142459  67.31477622 169.89467973 194.33768683\n",
      " 110.12740475  90.68069548 241.33792688 118.60464354 472.98144864\n",
      " 172.44236414 200.69976533 184.2679261  133.68621016 103.89319656\n",
      " 437.40563119 122.8496143  215.09186656 169.25948304 256.14748618\n",
      " 108.78036771  89.01020681 107.27735092 104.3796621  206.53386952\n",
      " 160.8933355  131.71380106 162.59687398 197.1808475  132.70555553\n",
      " 121.62548247 233.49179434 153.03063937 119.03003463 153.63260081\n",
      " 447.75659476 129.69855566 111.48025636  76.80674884 127.13514081\n",
      " 225.37734807  60.50774272 154.79306516 249.03265454 160.52187739\n",
      " 193.41797127  92.73029965 133.23951554 219.42140076  77.29688705\n",
      " 152.04237811  53.46376669  97.45680041 109.06843435 278.27743122\n",
      "  91.67562663  99.31980032 188.62643481 119.01184706  92.93285076\n",
      " 106.72718411 790.95382417 240.03976399 175.83215405 137.41199764\n",
      " 190.6519842  697.08256689 115.46036308 105.11697881 232.99949616\n",
      "  82.38765011 126.92543345 101.96242695 171.05365572 142.36820359\n",
      " 143.7821696  140.95055193  88.99000688 625.12172055 129.458837\n",
      " 119.79460344 122.46030594  78.35567728 133.35457754 279.60875709\n",
      " 153.79960489 163.73463948  98.7446091   49.28197485  91.51788591\n",
      "  96.79945304 125.20133715 141.48441319  62.06302605  72.869099\n",
      " 126.06178816  74.57258609 140.67923156 148.14345014 143.01536021\n",
      " 123.4598782  139.15293694 116.73274848 156.99587505 327.45635806\n",
      " 115.94530251 141.65010138 105.6097952  125.59241084  81.58173807\n",
      "  55.88959286  94.76545703 125.50359556  69.20202417 113.31955238\n",
      " 376.185839    67.20315176 277.61598776  81.22143649  93.83823315\n",
      " 138.46274053 102.82484083 218.99068172 123.55399312 148.66274531\n",
      " 437.40541287  75.39728096 147.87230902 152.40807297 133.3673508\n",
      " 223.88301446  37.48921262 167.31235555 320.33277197  68.81693394\n",
      "  68.94560917 105.29676443 140.17997594  99.3796882  241.241644\n",
      " 182.33333335  69.44124133  78.62729228  85.47766519 148.99954908\n",
      " 153.95818336  20.02370784  64.76915238  67.18983184 131.59589422\n",
      "  98.69107956 388.29021749 146.18143393 219.60007318 179.90160214\n",
      "  89.73659918 120.65570026 104.95729633 249.06243081 167.79797808\n",
      " 100.70252482  93.72609668 113.64211979 115.30962067 147.4220371\n",
      " 171.35554292 110.19780247  43.28668605 321.37924294 136.1221076\n",
      "  55.6541776   56.97780821 148.74420499  74.83842171 150.08792774]\n"
     ]
    }
   ],
   "source": [
    "X_train1 = X_train[0:1000][numberCols].to_numpy()\n",
    "X_test1 = X_test[0:1000][numberCols].to_numpy()\n",
    "y_train1 = y_train[0:1000].to_numpy()[:,0]\n",
    "y_test1 = y_test[0:1000].to_numpy()[:,0]\n",
    "\n",
    "knnr = KNNRegressor(n_neighbors = 3, metric = 'euclidean', mode = 'distance')\n",
    "knnr.fit(X_train1, y_train1)\n",
    "res = knnr.predict(X_test1)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.1 (1 балл)</b>\n",
    "Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на [третьем семинаре](https://github.com/mmp-mmro-team/mmp_mmro_fall_2019/blob/master/lecture-notes/Sem03_knn.pdf). Не забудьте, что KNNRegressor должен уметь работать с этими функциями расстояния. Как вариант, можно реализовать метрики как [user-defined distance](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(x, z):\n",
    "    # Ваш код здесь\n",
    "    dist = 0\n",
    "    for i in range(len(x)):\n",
    "        if (x[i] != z[i]):\n",
    "            dist = 1\n",
    "            break\n",
    "    return dist\n",
    "\n",
    "def flattened_overlap(x, z):\n",
    "    # Ваш код здесь\n",
    "    pass\n",
    "\n",
    "def log_overlap(x, z):\n",
    "    # Ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131.33333333  87.         314.33333333  98.66666667 124.33333333\n",
      " 103.33333333  80.          51.66666667 249.66666667 408.33333333\n",
      " 131.66666667  69.33333333  81.33333333 102.66666667 260.\n",
      "  83.          96.33333333 161.66666667 111.66666667  81.66666667\n",
      " 266.66666667  85.66666667 111.          70.33333333  90.66666667\n",
      " 102.66666667 298.          91.33333333  82.33333333 436.66666667\n",
      " 103.33333333 408.         115.33333333 206.66666667 253.33333333\n",
      "  96.66666667 135.         196.66666667 107.66666667 169.33333333\n",
      "  88.          71.66666667  87.66666667 164.66666667 178.33333333\n",
      " 188.         183.         277.66666667 110.          71.66666667\n",
      " 113.33333333 112.33333333  91.33333333  99.33333333 190.33333333\n",
      "  98.33333333  84.33333333  75.         107.33333333 198.\n",
      "  88.          79.33333333 168.          98.33333333  95.\n",
      "  92.66666667  91.66666667  76.         176.66666667 140.33333333\n",
      "  50.         104.33333333  95.         206.         172.33333333\n",
      " 115.         100.         130.          90.         134.\n",
      " 143.66666667 247.33333333 194.66666667 178.33333333 128.33333333\n",
      "  96.66666667 160.         335.          60.33333333  80.\n",
      "  83.33333333 126.66666667 103.33333333 118.33333333 104.66666667\n",
      " 117.          99.         178.33333333 103.         172.\n",
      " 193.33333333  76.66666667  85.         151.66666667 116.66666667\n",
      " 160.         102.33333333 163.33333333  83.         121.33333333\n",
      " 105.66666667  66.33333333 193.          51.66666667  68.33333333\n",
      " 446.33333333 164.66666667 109.33333333 120.66666667 210.\n",
      " 110.33333333 273.         131.33333333 496.66666667 160.\n",
      " 118.         103.33333333  93.         142.66666667  67.33333333\n",
      " 136.66666667  94.66666667 134.         175.         170.66666667\n",
      " 104.66666667 109.33333333 120.66666667 116.         242.66666667\n",
      " 158.          73.         188.66666667 178.66666667  90.\n",
      " 198.         119.33333333 254.33333333 326.33333333 162.66666667\n",
      " 270.          50.         259.66666667 128.33333333 153.33333333\n",
      " 102.66666667 157.33333333 128.33333333 208.          96.33333333\n",
      "  95.33333333  66.66666667 114.66666667 158.33333333  76.66666667\n",
      " 124.          90.         118.66666667 156.66666667 178.33333333\n",
      " 111.33333333 221.66666667 169.33333333 426.33333333 290.66666667\n",
      "  71.66666667 115.         123.         130.         143.66666667\n",
      " 151.66666667  94.66666667 121.66666667 168.         169.33333333\n",
      "  97.         294.          88.33333333  91.66666667  74.33333333\n",
      " 150.66666667 444.66666667  86.66666667 123.         128.66666667\n",
      " 312.33333333  83.33333333 166.66666667 179.66666667 148.33333333\n",
      "  73.33333333  80.66666667  63.         189.          71.66666667\n",
      "  71.         125.         181.66666667 113.33333333 143.33333333\n",
      " 101.66666667 111.          75.33333333 131.66666667 147.33333333\n",
      " 335.33333333 130.         210.66666667 172.33333333 169.33333333\n",
      " 233.33333333  82.         123.33333333 281.66666667 133.33333333\n",
      " 103.33333333 151.         183.33333333 108.33333333  70.66666667\n",
      " 210.66666667 130.         126.33333333 342.         153.33333333\n",
      " 173.33333333 130.         109.66666667 127.33333333 100.\n",
      "  73.33333333  60.66666667  91.66666667 117.33333333  51.66666667\n",
      " 143.33333333  75.33333333 122.33333333 172.66666667  96.66666667\n",
      "  67.66666667 115.         126.66666667  77.         130.66666667\n",
      " 170.66666667 188.         383.33333333 181.33333333 101.66666667\n",
      " 143.33333333 113.33333333  81.33333333  98.33333333  62.\n",
      " 165.66666667 143.66666667 232.33333333  95.66666667 107.33333333\n",
      "  94.66666667  80.         133.         162.66666667 112.33333333\n",
      " 119.33333333 120.66666667 239.33333333  95.         115.66666667\n",
      "  70.66666667 118.66666667 143.33333333 172.33333333 128.33333333\n",
      " 113.         125.66666667  94.         178.33333333  76.66666667\n",
      " 153.33333333 115.          58.33333333 176.          88.33333333\n",
      " 138.33333333 116.33333333 115.         425.         130.\n",
      "  88.         141.33333333 105.         176.33333333 408.33333333\n",
      " 150.         176.66666667 222.66666667 169.33333333 129.\n",
      " 106.         139.66666667 129.         159.66666667 105.\n",
      "  70.          76.         128.33333333 126.33333333 146.\n",
      " 103.33333333 194.33333333 139.33333333 211.66666667  62.33333333\n",
      " 123.33333333 243.66666667 123.33333333 138.66666667 144.33333333\n",
      " 142.66666667 104.66666667 125.66666667 138.         120.66666667\n",
      " 231.33333333  62.33333333 233.33333333 118.          76.66666667\n",
      " 446.33333333 124.66666667  92.         183.33333333  77.\n",
      "  74.33333333 170.          78.66666667 116.66666667 181.66666667\n",
      " 181.33333333 127.66666667 127.33333333  89.         140.33333333\n",
      " 162.         191.33333333  82.33333333 148.33333333  75.\n",
      " 187.         226.66666667 157.33333333  98.         157.33333333\n",
      "  84.33333333 201.33333333  83.33333333 139.33333333 124.\n",
      "  82.         318.         391.33333333  97.33333333 135.66666667\n",
      " 123.33333333 152.          71.66666667  97.66666667 190.\n",
      " 343.33333333 111.66666667 102.66666667 181.66666667 103.33333333\n",
      " 133.33333333 171.33333333 113.33333333 232.33333333 124.66666667\n",
      " 169.33333333 270.         149.66666667  79.66666667 135.\n",
      " 153.         137.66666667  80.         142.         113.33333333\n",
      " 166.33333333 125.         140.66666667 107.          79.66666667\n",
      " 214.66666667 163.         468.          57.         357.33333333\n",
      " 131.33333333 213.         301.33333333 220.         152.\n",
      " 100.         123.33333333 104.33333333 160.         194.\n",
      " 114.33333333  98.         108.33333333  99.         120.33333333\n",
      " 250.         222.66666667  59.33333333 149.66666667 104.\n",
      " 109.66666667  86.66666667 230.         128.         168.\n",
      " 189.66666667 101.66666667  63.         190.          88.33333333\n",
      "  81.66666667 218.         101.66666667  65.         105.66666667\n",
      " 197.66666667 126.         181.66666667 166.33333333  99.33333333\n",
      " 101.         167.66666667  76.66666667  91.         148.33333333\n",
      " 133.33333333 250.33333333 129.66666667 109.33333333  94.66666667\n",
      " 140.          79.66666667 184.33333333 171.33333333  88.\n",
      " 249.66666667 222.66666667 125.          93.33333333  92.33333333\n",
      "  86.         104.33333333 156.33333333 294.66666667  90.\n",
      " 158.         128.          59.33333333 231.33333333 102.66666667\n",
      "  86.33333333 197.66666667  75.66666667 161.          80.\n",
      " 182.66666667 158.33333333 233.         158.33333333 125.\n",
      " 156.33333333  76.66666667  85.         103.33333333 119.66666667\n",
      " 125.          90.         104.          82.33333333 100.\n",
      " 222.66666667  79.          80.         128.33333333  84.\n",
      " 242.66666667 139.66666667 240.         155.         128.33333333\n",
      " 105.66666667  89.         111.         185.         227.66666667\n",
      " 157.33333333 104.66666667  95.         196.66666667 340.66666667\n",
      " 158.33333333 111.66666667 339.33333333  64.66666667 178.\n",
      " 118.33333333  88.         393.33333333  81.66666667 150.\n",
      "  71.         118.66666667 125.33333333 187.66666667 286.66666667\n",
      " 105.33333333 154.33333333  62.33333333  56.66666667  86.33333333\n",
      " 171.66666667 190.         166.66666667 102.66666667  87.66666667\n",
      " 123.          76.66666667 112.         202.33333333 114.66666667\n",
      "  81.66666667  84.          54.33333333 153.33333333  93.33333333\n",
      " 304.33333333 123.33333333 104.33333333 205.          88.33333333\n",
      " 216.          51.66666667 178.33333333 179.         118.\n",
      " 103.33333333 227.66666667 286.66666667 115.66666667  82.\n",
      "  96.66666667  97.33333333 234.66666667 120.         112.66666667\n",
      " 125.          78.         138.33333333  89.         263.33333333\n",
      " 228.33333333 139.66666667 131.33333333 143.66666667 183.\n",
      " 150.66666667 141.33333333 137.33333333 136.66666667 104.66666667\n",
      "  96.33333333 619.         110.          91.66666667 254.66666667\n",
      " 100.         101.         139.66666667 125.          86.33333333\n",
      " 159.66666667 222.66666667 171.33333333 118.         185.\n",
      " 131.66666667  79.33333333  91.66666667 336.          75.66666667\n",
      " 127.          90.66666667 133.33333333 159.33333333 195.66666667\n",
      "  97.         222.66666667 127.         224.66666667 220.\n",
      " 161.         109.66666667 124.66666667  79.         136.66666667\n",
      " 184.33333333 111.66666667 151.33333333 124.         106.66666667\n",
      " 189.33333333 187.33333333 178.33333333 184.66666667 134.\n",
      " 190.         154.         179.33333333 147.33333333  95.\n",
      "  95.          88.         226.66666667 153.          84.33333333\n",
      "  85.33333333 101.66666667 106.66666667  80.          75.\n",
      " 131.66666667  80.          63.66666667 115.         147.66666667\n",
      " 149.66666667 163.          94.33333333 164.66666667 190.\n",
      "  66.         103.33333333  86.66666667  57.33333333 111.\n",
      " 216.66666667 221.33333333 270.         281.66666667 130.\n",
      " 131.33333333 144.33333333 343.33333333 125.          78.\n",
      "  64.66666667 273.33333333 186.         121.66666667  65.33333333\n",
      "  86.66666667 158.66666667  86.66666667 156.66666667 149.66666667\n",
      " 106.66666667 189.33333333 159.         200.          87.33333333\n",
      "  44.33333333  91.66666667  83.33333333 130.33333333  88.\n",
      "  82.         119.66666667 150.33333333 170.33333333 115.\n",
      " 133.          74.33333333 125.66666667  86.66666667  91.\n",
      "  95.66666667 198.33333333 144.33333333 174.66666667 123.33333333\n",
      " 168.33333333 133.33333333 159.33333333 191.33333333 188.33333333\n",
      " 281.66666667 153.66666667  76.          86.66666667 189.\n",
      " 159.         103.33333333 174.66666667  73.66666667 123.\n",
      " 128.33333333 144.66666667 131.66666667 178.33333333  76.66666667\n",
      "  96.33333333  56.33333333 298.         187.66666667  91.66666667\n",
      " 160.33333333 162.66666667  93.          65.         100.\n",
      "  73.         293.33333333 114.66666667 127.         119.33333333\n",
      " 147.33333333  83.66666667  81.         142.66666667  96.66666667\n",
      " 125.          96.66666667 135.          74.33333333 336.33333333\n",
      " 121.33333333 135.         163.33333333 130.         123.33333333\n",
      " 222.66666667 100.33333333 172.66666667  62.66666667  73.33333333\n",
      " 145.         136.66666667 255.         144.          82.\n",
      "  75.         156.66666667 238.         134.          95.\n",
      " 220.         165.         143.33333333 302.33333333 104.66666667\n",
      " 133.33333333  74.66666667  68.         117.33333333  87.66666667\n",
      " 195.         305.         446.33333333 220.33333333 115.66666667\n",
      "  66.         173.33333333  60.         126.66666667  92.\n",
      " 133.         110.         221.          68.66666667 128.33333333\n",
      " 258.33333333 126.33333333 129.         169.66666667  90.\n",
      " 136.66666667 138.33333333 218.          99.33333333 147.33333333\n",
      "  81.         160.         165.         606.33333333 116.66666667\n",
      "  62.33333333  91.66666667 116.66666667 110.         143.33333333\n",
      " 103.33333333 181.          65.         102.66666667 134.33333333\n",
      " 220.33333333 198.          90.         145.         286.\n",
      " 110.33333333 126.33333333 190.         104.33333333 181.66666667\n",
      " 183.         176.66666667 101.         168.          67.66666667\n",
      " 233.          68.66666667 105.66666667 256.         165.\n",
      "  81.66666667 176.66666667 181.33333333 105.66666667 165.\n",
      "  95.         268.33333333 273.33333333 298.          74.\n",
      "  78.33333333 208.         165.         173.          78.33333333\n",
      " 133.33333333 128.33333333  71.         248.66666667 101.66666667\n",
      " 111.66666667 159.33333333 123.33333333  61.66666667 146.66666667\n",
      " 130.33333333  89.         191.66666667 181.66666667 161.66666667\n",
      " 106.33333333 110.66666667 218.         170.66666667 204.\n",
      " 139.66666667 138.33333333  67.         293.          98.66666667\n",
      " 149.33333333  70.         143.66666667 118.33333333 118.33333333\n",
      " 134.33333333 194.66666667  46.33333333 175.         148.\n",
      "  98.33333333  71.66666667 249.         186.66666667  58.33333333\n",
      "  85.         336.66666667  62.66666667  76.66666667 166.33333333\n",
      "  93.33333333 223.33333333  68.33333333  88.         156.66666667\n",
      "  76.          91.66666667  81.66666667 120.         249.66666667\n",
      " 169.         149.66666667  91.33333333 146.33333333  91.66666667\n",
      " 169.33333333 115.         157.         134.66666667 170.\n",
      "  75.         131.66666667  83.33333333  63.66666667 216.33333333\n",
      "  68.66666667  75.66666667  95.          71.         152.66666667\n",
      " 119.66666667 205.          85.         161.66666667 143.33333333\n",
      " 100.         177.33333333 118.33333333 167.33333333 191.66666667\n",
      " 181.33333333 183.66666667 187.66666667  83.         113.\n",
      " 379.         273.33333333 135.          91.66666667  70.\n",
      " 222.66666667  88.33333333 125.         632.66666667 139.33333333\n",
      " 105.         111.         142.         206.66666667  58.33333333\n",
      " 146.66666667  73.33333333 177.          83.33333333 106.66666667\n",
      " 468.33333333  87.66666667 211.         140.          76.66666667\n",
      " 168.         222.66666667  68.33333333 186.66666667  84.\n",
      "  79.         214.          93.66666667 133.         274.66666667\n",
      " 148.66666667 138.33333333  83.33333333 117.33333333 115.\n",
      " 129.66666667 103.         298.33333333 201.         181.33333333\n",
      " 109.66666667 113.33333333 154.          68.33333333 181.66666667]\n"
     ]
    }
   ],
   "source": [
    "X_train1 = X_train[0:1000][categoricalCols].to_numpy()\n",
    "X_test1 = X_test[0:1000][categoricalCols].to_numpy()\n",
    "y_train1 = y_train[0:1000].to_numpy()[:,0]\n",
    "y_test1 = y_test[0:1000].to_numpy()[:,0]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X_train1[:, 0] = labelencoder.fit_transform(X_train1[:, 0])\n",
    "X_train1[:, 1] = labelencoder.fit_transform(X_train1[:, 1])\n",
    "X_train1[:, 2] = labelencoder.fit_transform(X_train1[:, 2])\n",
    "X_train1[:, 3] = labelencoder.fit_transform(X_train1[:, 3])\n",
    "X_train1[:, 4] = labelencoder.fit_transform(X_train1[:, 4])\n",
    "X_train1[:, 5] = labelencoder.fit_transform(X_train1[:, 5])\n",
    "\n",
    "X_test1[:, 0] = labelencoder.fit_transform(X_test1[:, 0])\n",
    "X_test1[:, 1] = labelencoder.fit_transform(X_test1[:, 1])\n",
    "X_test1[:, 2] = labelencoder.fit_transform(X_test1[:, 2])\n",
    "X_test1[:, 3] = labelencoder.fit_transform(X_test1[:, 3])\n",
    "X_test1[:, 4] = labelencoder.fit_transform(X_test1[:, 4])\n",
    "X_test1[:, 5] = labelencoder.fit_transform(X_test1[:, 5])\n",
    "\n",
    "\n",
    "knnr = KNNRegressor(n_neighbors = 3, metric = 'euclidean', mode = 'uniform')\n",
    "knnr.fit(X_train1, y_train1)\n",
    "res = knnr.predict(X_test1)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.2 (1 балл)</b> Найдите все категориальные признаки в данных. Подсчитайте для каждой из метрик качество на тестовой выборке `X_test` при числе соседей $k = 10$. Качество измеряйте с помощью RMSE.\n",
    "\n",
    "Какая функция расстояния оказалась лучшей? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'host_name',\n",
       " 'neighbourhood_group',\n",
       " 'neighbourhood',\n",
       " 'room_type',\n",
       " 'last_review']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "categoricalCols = numberCols = X_test.select_dtypes(include=[object]).columns.tolist()\n",
    "categoricalCols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.3 (1 балл) бонус</b> Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какого удалось достичь уровня качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.4 (2.5 балла)</b> Отойдем ненадолго от задачи регрессии и перейдём к задаче классификации: будем определять, являеться ли квартира дорогой $(target = 1)$ или дешевой $(target = 0)$. Будем считать дорогими квариры, цена которых выше среднего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['target'] = (data.price > data.price.mean()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте счетчики, которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, для каждого категориального признака $f_j(x)$ необходимо сделать следующее:\n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "\\begin{align}\n",
    "counts_j(c) = \\sum_{i=1}^l [f_j(x_i) = c]\n",
    "\\end{align}\n",
    "2. Число `successes` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "\\begin{align}\n",
    "successes_j(c) = \\sum_{i=1}^l[f_j(x_i) = c][y_i = +1].\n",
    "\\end{align}\n",
    "3. Сглаженное отношение двух предыдущих величин:\n",
    "\\begin{align}\n",
    "p_j(c) = \\frac{successes_j(c) + a}{counts_j(c) + b},\n",
    "\\end{align}\n",
    "\n",
    "где $a$ и $b$ - априорные счетчики (например, a = 1, b = 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counters(x):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        x: value on categorical feature for N objects\n",
    "    returns: vector of length N\n",
    "    \"\"\"\n",
    "    # Ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `successes` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанный по всей обучающей выборке. Реализуйте и такой вариант. Достаточно взять $n = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fold_counters(x):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        x: value on categorical feature for N objects\n",
    "    returns: vector of length N\n",
    "    \"\"\"\n",
    "    # Ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.5 (1 балл)</b> Вернемся к задаче регрессии. Утверждается, что для задачи регрессии можно также сделать преобразование категориальных признаков в действительные числа. Для этого достаточно для каждого значения признака $f_j$ вычислить:\n",
    "\\begin{align}\n",
    "p_j(c) = g(T_i | f_j(x_i) = c),\n",
    "\\end{align}\n",
    "\n",
    "где $T_i$ - значения целевой переменной объекта $x_i$. Функция $g$ - среднее (mean) или среднеквадратичное отклонение (std).\n",
    "\n",
    "Закодируйте категориальные признаки обоими способами и найдите значение RMSE. Используйте евклидову метрику для поиска ближайших соседей. Для какой функции $g$ значение RMSE лучше? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Текстовые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.1 (2 балла)</b> Перейдем от категориальным признаков к текстовым. Рассмотрим 2 способа преобразования текста в действительные числа:\n",
    "- Мешок слов (Bag of Words)\n",
    "- TF-IDF\n",
    "\n",
    "[Здесь](https://scikit-learn.org/stable/modules/feature_extraction.html) вы можете прочитать про их применение в Питоне.\n",
    "\n",
    "Сравните оба способа на задаче регресси. Какую лучше метрику использовать: евклидову или косинусную меру? Постройте графики зависимости качества решения задачи от способа преобразования, метрики и количества соседей. Мера качества - RMSE.\n",
    "\n",
    "Объясните полученные результаты.\n",
    "\n",
    "Перед преобразованием не забудьте уменьшить размер словаря. Например, это можно сделать за счет приведения всех слов к одному регистру и удаления [стопслов](https://en.wikipedia.org/wiki/Stop_words) (артиклей, предлогов, союзов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.2 (1 балл)</b> Используя все доступные признаки, решите задачу регрессии. Для категориальных и текстовых признаков выберите лучшие преобразования. Повлияло ли добавление количественного признака на метрику качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4: Выводы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваши выводы здесь (ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
