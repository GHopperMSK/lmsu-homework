{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Машинное обучение, ВМК МГУ\n",
    "\n",
    "## Практическое задание 2\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 9 октября 2019\n",
    "\n",
    "Максимальная оценка: 10 баллов + 1 бонусный балл\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 23 октября (за каждый день просрочки снимается 1 балл)\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 30 октября."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании вы:\n",
    "- Познакомитесь с методом решения задачи регрессии на основе метода ближайших соседей.\n",
    "- Реализуете алгоритм kNN для задачи регрессии.\n",
    "- Изучите методы работы с категориальными и текстовыми переменными.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл *.ipynb в соответствии со следующим форматом: homework-practice-02-Username.ipynb, где Username — ваша фамилия и имя на латинице именно в таком порядке (например, homework-practice-02-ivanov.ipynb).\n",
    "\n",
    "Далее отправьте этот файл на anytask в соответсвующий раздел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все эксперименты в этой лабораторной работе предлагается проводить на данных соревнования New York City Airbnb Open Data: https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data#AB_NYC_2019.csv\n",
    "\n",
    "В данной задаче предлагается предсказать цену на съем квартиры в зависимости от её параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('AB_NYC_2019.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48895, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 48895\n",
      "name 47906\n",
      "host_id 37457\n",
      "host_name 11453\n",
      "neighbourhood_group 5\n",
      "neighbourhood 221\n",
      "latitude 19048\n",
      "longitude 14718\n",
      "room_type 3\n",
      "price 674\n",
      "minimum_nights 109\n",
      "number_of_reviews 394\n",
      "last_review 1765\n",
      "reviews_per_month 938\n",
      "calculated_host_listings_count 47\n",
      "availability_365 366\n"
     ]
    }
   ],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print(col_name, len(data[col_name].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                    0\n",
       "name                                 16\n",
       "host_id                               0\n",
       "host_name                            21\n",
       "neighbourhood_group                   0\n",
       "neighbourhood                         0\n",
       "latitude                              0\n",
       "longitude                             0\n",
       "room_type                             0\n",
       "price                                 0\n",
       "minimum_nights                        0\n",
       "number_of_reviews                     0\n",
       "last_review                       10052\n",
       "reviews_per_month                 10052\n",
       "calculated_host_listings_count        0\n",
       "availability_365                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, в данных есть пропуски. Не забудьте обработать их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь (ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем данные на обучение и контроль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['price']), data[['price']],\n",
    "                                                    test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Алгоритм kNN в задаче регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1.1 (1.5 балла) </b>\n",
    "Реализуйте класс `KNNRegressor`, который используя метод k ближайших соседей решает задачу регрессии. Для решение данной задачи, необходимо найти $N_k$ - k соседей, и после использовать значения их целевых переменных для предсказания:\n",
    "\\begin{align}\n",
    "y = \\frac{1}{k}\\sum_{n \\in N_k}w_n y_n,\n",
    "\\end{align}\n",
    "\n",
    "где $w_n$ - вес каждого соседа. \n",
    "\n",
    "При этом `KNNRegressor` может работать в 2 режимах:\n",
    " - $uniform$ - ближайшие соседи учитываются с одинаковыми весами.\n",
    " - $distance$ - вес ближайших соседей зависит от расстояния\n",
    " \n",
    "Сигнатуру методов при желании можно менять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable, Iterable, Optional\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "class KNNRegressor:\n",
    "    def __init__(self, n_neighbors: int, metric: Union[str, Callable], mode: str = 'uniform'):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            n_neighbors: number of neighbors\n",
    "            metric: metric to use for distance computation\n",
    "            mode: 'uniform' or 'distance'\n",
    "            'uniform' - all points in each neighborhood are weighted equally\n",
    "            'distance' - weight points by the inverse of their distance\n",
    "        \"\"\"\n",
    "#         self.__nn = NearestNeighbors(n_neighbors = n_neighbors, metric = metric)\n",
    "#         self.__nnTest = KNeighborsRegressor(n_neighbors = n_neighbors, metric = metric, weights = mode)\n",
    "        self.__metric = metric\n",
    "        self.__mode = mode\n",
    "        self.__n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X: np.array, y: np.array) -> None:\n",
    "        \"\"\"\n",
    "            X: data\n",
    "            y: labels\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        self.__X = X\n",
    "        self.__y = y\n",
    "#         self.__nn.fit(X, y)\n",
    "#         self.__nnTest.fit(X, y)\n",
    "        \n",
    "    def euclidean_distance(self, X, Y):\n",
    "        d = len(X[0])\n",
    "        res = np.zeros(len(X)*len(Y)).reshape(len(X), len(Y))\n",
    "        for x in range(len(X)):\n",
    "            for y in range(len(Y)):\n",
    "                sum = 0\n",
    "                for f in range(len(Y[y])):\n",
    "                    sum += (X[x][f] - Y[y][f])**2\n",
    "                res[x][y] = np.sqrt(sum)\n",
    "        return res;\n",
    "\n",
    "    def cosine_distance(self, X, Y):\n",
    "        sumyy = (Y**2).sum(1)\n",
    "        sumxx = (X**2).sum(1, keepdims=1)\n",
    "        sumxy = X.dot(Y.T)\n",
    "        return 1 - (sumxy/np.sqrt(sumxx))/np.sqrt(sumyy)\n",
    "    \n",
    "    def overlap(self, X, Y):\n",
    "        res = []\n",
    "        for row in range(len(X)):\n",
    "            distRow = []\n",
    "            for col in range(len(X[row])):\n",
    "                if (X[row][col] == Y[row][col]):\n",
    "                    distRow.append(0)\n",
    "                else:\n",
    "                    distRow.append(1)\n",
    "            res.append(distRow)\n",
    "        return np.array(res)\n",
    "    \n",
    "    def find_kneighbors(self, X, return_distance = True):\n",
    "        res = []\n",
    "        dists = []\n",
    "\n",
    "        if (self.__metric == 'euclidean'):\n",
    "            dsModRes = self.euclidean_distance(X, self.__X)\n",
    "        elif (self.__metric == 'cosine'):\n",
    "            dsModRes = self.cosine_distance(X, self.__X)\n",
    "        elif (self.__metric == 'overlap'):\n",
    "            dsModRes = self.overlap(X, self.__X)\n",
    "        else:\n",
    "            raise Exception(\"Unknown 'metric' param value\")\n",
    "\n",
    "        for i in range(len(dsModRes)):\n",
    "            tmpDists = np.argsort(dsModRes[i])[:self.__n_neighbors]\n",
    "            res.append(dsModRes[i][tmpDists])\n",
    "            if (return_distance):\n",
    "                dists.append(tmpDists)\n",
    "\n",
    "        if (return_distance):\n",
    "            return (res, dists)\n",
    "        else:\n",
    "            return (res)\n",
    "        \n",
    "    def predict(self, X: np.array, n_neighbors: Optional[int] = None) -> np.array:\n",
    "        \"\"\"\n",
    "            X: data\n",
    "            n_neighbors: number of neighbors\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "#         distances, indices = self.__nn.kneighbors(X)\n",
    "        distances, indices = self.find_kneighbors(X)\n",
    "\n",
    "        if (self.__mode == 'uniform'):\n",
    "            res = self.__y[indices].mean(axis=1)\n",
    "        else: \n",
    "            res = []\n",
    "            for row in range(len(indices)):\n",
    "                predictedVal = 0\n",
    "                for col in range(len(indices[row])):\n",
    "                    w = 1 - ((distances[row][col] - min(distances[row])) /\n",
    "                             (1 + max(distances[row]) - min(distances[row])))\n",
    "                    predictedVal = predictedVal + w * self.__y[indices[row][col]]\n",
    "                res.append(predictedVal / len(indices[row]))\n",
    "            res = np.array(res)\n",
    "#         return self.__nnTest.predict(X)\n",
    "        return res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 86.66666667 333.33333333 260.         154.66666667 125.33333333\n",
      "  70.         199.66666667 181.33333333 333.33333333  75.66666667\n",
      " 241.66666667 140.          86.66666667  87.66666667 218.66666667\n",
      "  88.66666667  90.33333333 130.         186.66666667 113.\n",
      " 187.66666667 186.         195.          90.          86.66666667\n",
      " 119.66666667  79.33333333  63.         130.         120.\n",
      " 193.33333333 115.66666667  63.         111.         114.33333333\n",
      " 183.33333333  56.33333333 129.33333333 183.33333333 212.33333333\n",
      " 130.          68.33333333 176.66666667 319.66666667 104.66666667\n",
      " 164.33333333 143.33333333  65.66666667 111.66666667  77.66666667\n",
      " 270.         146.66666667 101.66666667 134.66666667 139.33333333\n",
      " 129.          61.33333333  99.33333333 149.66666667  62.\n",
      "  71.66666667  74.66666667  68.33333333  98.66666667  57.33333333\n",
      " 113.33333333  85.66666667  98.         114.33333333 240.\n",
      " 178.33333333  84.66666667 105.66666667  88.33333333 187.66666667\n",
      " 110.66666667 111.33333333 175.          63.          71.\n",
      " 123.33333333  99.         116.66666667 135.66666667 175.33333333\n",
      "  68.33333333  99.33333333  63.         112.66666667  99.33333333\n",
      "  99.33333333 123.         194.66666667 123.          93.33333333\n",
      " 108.33333333 148.33333333 113.33333333 270.         126.\n",
      " 134.66666667  84.          91.66666667 228.         133.33333333\n",
      " 151.33333333  91.66666667 183.33333333 134.         105.66666667\n",
      "  71.33333333  97.33333333 175.33333333 196.66666667  70.\n",
      " 121.         138.66666667 401.33333333 141.33333333 178.33333333\n",
      "  68.33333333 113.33333333 136.         356.33333333 256.66666667\n",
      " 121.66666667 313.33333333 106.33333333 175.         123.\n",
      " 123.         160.         189.66666667 200.         132.66666667\n",
      " 116.         180.33333333 136.66666667 141.33333333 120.\n",
      " 209.66666667 188.33333333 150.         200.         209.66666667\n",
      "  62.         153.33333333  82.66666667  78.66666667 189.\n",
      " 134.33333333 107.33333333 114.33333333  62.         156.66666667\n",
      "  97.33333333 109.          55.         111.33333333 105.\n",
      " 149.66666667  88.66666667 135.33333333 189.66666667 140.\n",
      " 114.33333333 145.          76.66666667  93.33333333 126.66666667\n",
      " 123.66666667  93.33333333 426.66666667 130.         154.66666667\n",
      " 256.66666667 190.          92.66666667  87.33333333 121.66666667\n",
      " 204.66666667 128.33333333 138.33333333 126.66666667  53.\n",
      " 146.66666667 129.          98.         188.33333333 111.66666667\n",
      " 156.66666667 108.66666667 147.          66.66666667 153.33333333\n",
      " 199.33333333  93.33333333  93.33333333 148.33333333  55.\n",
      "  78.         119.66666667 112.66666667  54.33333333  71.66666667\n",
      " 189.66666667  56.33333333 150.         229.66666667 154.66666667\n",
      " 173.33333333 125.66666667 183.         171.33333333 115.\n",
      "  98.         177.66666667 140.33333333 100.         200.\n",
      " 136.66666667 346.33333333  93.33333333 109.         106.33333333\n",
      " 173.66666667 120.         146.66666667 181.33333333  56.33333333\n",
      " 127.33333333 107.33333333 127.33333333  84.66666667 143.\n",
      " 113.          56.66666667 131.66666667  88.33333333 212.33333333\n",
      " 145.66666667  68.33333333 136.66666667 108.33333333 313.33333333\n",
      "  71.         130.66666667 123.         222.66666667 129.\n",
      "  93.33333333  71.         145.66666667 213.33333333  96.33333333\n",
      " 172.          97.66666667  95.          88.66666667  40.\n",
      " 105.         110.66666667 143.33333333 129.33333333 166.33333333\n",
      " 162.66666667 120.         118.33333333 195.         129.\n",
      " 149.33333333 136.         134.         132.33333333 176.66666667\n",
      " 320.33333333 106.33333333 260.         121.66666667 190.\n",
      " 313.66666667 188.33333333 120.         100.          67.\n",
      "  61.66666667 140.         257.66666667 298.66666667  56.66666667\n",
      " 235.         115.         123.         213.33333333  99.\n",
      "  74.66666667  82.66666667 193.66666667 146.66666667 164.33333333\n",
      " 129.          53.         136.66666667 116.          90.\n",
      " 147.33333333 127.66666667  96.33333333 120.         172.\n",
      " 145.         527.33333333  87.66666667 101.33333333 190.\n",
      "  71.66666667  98.66666667 172.          73.         231.33333333\n",
      " 166.33333333 126.         191.66666667 118.33333333 143.33333333\n",
      " 210.         156.66666667  75.66666667 488.33333333 135.\n",
      " 136.66666667 171.33333333  56.66666667 123.33333333  64.\n",
      " 110.          96.         191.66666667  94.         115.\n",
      " 187.66666667 111.33333333 156.66666667  94.33333333  84.\n",
      " 134.66666667 178.66666667 106.33333333  98.         101.66666667\n",
      " 136.         104.         119.          91.66666667  86.33333333\n",
      "  57.         111.33333333  77.33333333 178.33333333 176.66666667\n",
      " 149.66666667  56.66666667 118.33333333 178.33333333 161.33333333\n",
      " 121.         132.33333333 115.         113.         122.33333333\n",
      "  93.33333333  90.          61.33333333  87.33333333 130.\n",
      " 199.33333333  93.          88.         195.         148.33333333\n",
      " 179.33333333  70.          71.66666667 190.          61.\n",
      " 378.33333333 238.33333333 200.         212.33333333 110.\n",
      " 238.          85.         136.66666667 105.          71.66666667\n",
      " 313.33333333  79.33333333 228.33333333 113.         140.\n",
      " 199.66666667  99.66666667 105.         134.66666667 189.66666667\n",
      " 128.33333333 108.33333333 200.         116.66666667 120.66666667\n",
      " 143.33333333 346.33333333 119.66666667 163.66666667 260.\n",
      " 194.66666667  61.         117.33333333  66.66666667  56.66666667\n",
      " 126.33333333 115.         130.         100.         179.66666667\n",
      " 113.         222.66666667 142.33333333 123.33333333 110.66666667\n",
      "  37.         132.66666667 118.33333333 346.33333333 114.33333333\n",
      " 129.33333333 248.33333333 107.         139.66666667  86.66666667\n",
      " 458.         148.33333333 183.33333333 120.66666667  95.\n",
      " 115.         179.66666667 116.66666667  46.33333333 126.66666667\n",
      " 608.         128.         139.          71.          45.66666667\n",
      " 119.66666667 106.66666667 135.33333333  48.33333333  64.\n",
      "  98.         149.33333333 121.33333333  54.33333333 105.\n",
      " 121.66666667 367.66666667  74.66666667 426.66666667  45.66666667\n",
      " 173.33333333 608.          75.         103.33333333 134.66666667\n",
      " 172.         130.         111.33333333 135.          49.66666667\n",
      " 105.         139.66666667 141.33333333 146.         126.\n",
      " 403.         105.         126.33333333 260.         108.33333333\n",
      " 108.33333333 187.         129.66666667  83.33333333 154.\n",
      "  85.         301.33333333 204.33333333 204.33333333  66.66666667\n",
      " 222.66666667  48.33333333 310.          89.66666667 112.66666667\n",
      "  90.33333333 183.         301.33333333 158.33333333 128.33333333\n",
      " 260.          98.33333333 164.33333333 135.66666667 114.33333333\n",
      " 163.33333333  84.         111.33333333  75.66666667 163.\n",
      "  81.          91.66666667 204.33333333  40.          85.33333333\n",
      " 150.33333333 149.66666667  98.66666667 112.66666667  52.\n",
      " 104.66666667 107.         319.66666667 125.         162.66666667\n",
      " 103.33333333 244.66666667 101.66666667  65.          40.\n",
      " 102.66666667 118.         118.66666667 313.66666667  98.66666667\n",
      " 149.33333333  96.         143.33333333  78.33333333 120.\n",
      " 156.66666667 115.33333333 102.66666667 202.66666667  69.33333333\n",
      "  46.33333333 193.66666667  84.          91.66666667 120.66666667\n",
      " 125.66666667  64.         393.          61.33333333 123.66666667\n",
      " 171.33333333 143.         181.33333333 260.          83.33333333\n",
      " 113.         106.33333333  63.         106.         310.\n",
      "  77.66666667 110.         207.66666667  93.33333333 212.33333333\n",
      " 241.66666667 119.66666667 133.33333333  87.33333333 100.66666667\n",
      " 207.66666667  97.         190.         218.33333333  50.\n",
      "  86.33333333 127.66666667 115.          97.         193.66666667\n",
      " 138.         136.         189.          85.33333333 116.66666667\n",
      " 100.66666667 367.66666667  99.          91.66666667 195.\n",
      " 179.66666667 180.66666667 248.33333333  55.          90.\n",
      " 208.33333333 149.33333333 112.33333333 196.33333333 135.33333333\n",
      " 179.66666667 367.66666667 238.33333333 116.         103.33333333\n",
      " 115.         126.33333333  71.33333333 140.         109.66666667\n",
      " 120.         195.         163.         200.         135.66666667\n",
      "  92.66666667 134.33333333  84.         148.         200.\n",
      " 150.         446.33333333 100.         135.66666667  77.66666667\n",
      " 476.66666667  54.         204.66666667 183.33333333 106.33333333\n",
      " 133.66666667 312.66666667 195.66666667 146.66666667  91.66666667\n",
      " 123.          93.33333333 179.66666667 173.33333333 121.\n",
      " 161.33333333  87.33333333 204.33333333 134.66666667 119.\n",
      "  72.33333333  77.33333333 291.66666667 199.33333333 123.33333333\n",
      " 268.          85.33333333  86.66666667 182.33333333  40.\n",
      "  97.         136.66666667 123.33333333 145.66666667 140.33333333\n",
      " 179.33333333 172.         118.33333333 135.66666667 183.33333333\n",
      " 105.66666667  77.66666667  70.         115.66666667 485.66666667\n",
      " 180.66666667 177.66666667  85.33333333 113.66666667 179.33333333\n",
      " 128.33333333 302.33333333 375.          97.         126.33333333\n",
      " 186.33333333 141.66666667 205.66666667 102.66666667  49.66666667\n",
      "  79.33333333 110.66666667  83.33333333 312.66666667 136.\n",
      "  87.66666667 153.         134.33333333  76.66666667 141.\n",
      "  77.          75.66666667  57.         115.         119.33333333\n",
      " 101.66666667 110.         166.66666667 156.66666667  71.66666667\n",
      "  68.33333333 193.33333333 201.33333333 113.         119.66666667\n",
      " 330.         157.33333333 120.         145.         115.\n",
      " 145.66666667 128.33333333 101.66666667 153.         148.33333333\n",
      " 139.         161.66666667  76.66666667  87.66666667 136.66666667\n",
      " 175.         151.33333333 253.         111.66666667 119.66666667\n",
      " 146.66666667 488.33333333 127.66666667 186.33333333 204.33333333\n",
      "  93.33333333  40.         127.33333333 145.          92.66666667\n",
      " 112.66666667  87.66666667 103.33333333 138.66666667 146.66666667\n",
      " 222.66666667 118.33333333 204.33333333  96.33333333 118.\n",
      " 110.66666667  99.66666667  99.33333333 298.33333333 161.66666667\n",
      " 115.         111.33333333  55.33333333  56.66666667 108.33333333\n",
      " 362.66666667  61.66666667  65.         104.66666667 171.33333333\n",
      " 142.66666667  53.         164.          92.          56.66666667\n",
      "  95.33333333 312.66666667 204.33333333 124.66666667  86.66666667\n",
      " 106.33333333 200.          96.33333333 149.66666667 101.66666667\n",
      "  86.66666667 298.66666667 202.66666667 129.         248.33333333\n",
      "  48.33333333 124.33333333 134.66666667 121.33333333 139.66666667\n",
      "  79.33333333 139.33333333 221.66666667 161.33333333 173.33333333\n",
      " 195.66666667 148.33333333 145.         123.33333333  85.\n",
      " 181.33333333 149.33333333 120.         186.33333333  54.\n",
      "  79.66666667  86.33333333 141.66666667 113.33333333 118.\n",
      " 106.33333333  76.66666667  64.         178.33333333 196.33333333\n",
      " 113.33333333 140.         229.66666667  99.66666667 375.\n",
      " 147.         195.         195.         123.         121.\n",
      " 313.33333333 149.66666667 256.66666667 204.33333333 212.33333333\n",
      " 125.          98.66666667 105.         145.         148.33333333\n",
      " 148.33333333 123.33333333 183.         186.33333333 210.\n",
      "  94.33333333 216.66666667 141.         112.66666667 150.\n",
      " 480.         106.         111.33333333  79.33333333  99.66666667\n",
      " 150.          68.33333333 139.33333333 194.66666667 181.33333333\n",
      " 159.66666667 117.66666667 118.66666667 187.66666667  96.33333333\n",
      " 121.         113.33333333 128.33333333 173.33333333 320.33333333\n",
      " 105.          76.66666667  94.         118.33333333  91.66666667\n",
      " 105.         488.33333333 238.33333333 175.33333333 166.33333333\n",
      " 161.66666667 608.         119.66666667 130.66666667 139.\n",
      "  83.33333333 118.66666667 110.66666667 121.66666667 135.\n",
      " 100.66666667 148.33333333  86.66666667 401.33333333 129.\n",
      " 112.66666667 121.33333333  79.33333333 200.         260.\n",
      " 150.         183.33333333 106.66666667  97.33333333  93.33333333\n",
      "  93.         446.33333333 127.33333333  63.          93.\n",
      " 106.66666667  76.66666667 136.66666667 146.66666667 121.66666667\n",
      " 105.         166.33333333 113.         149.33333333 488.33333333\n",
      "  96.33333333 123.         446.33333333 112.33333333  96.33333333\n",
      " 135.66666667 140.33333333 123.          66.         111.33333333\n",
      " 485.          93.33333333 185.66666667  87.33333333  95.\n",
      " 148.33333333  76.66666667 187.66666667 111.33333333 133.33333333\n",
      " 313.33333333  98.66666667 117.33333333 200.         116.\n",
      " 222.66666667  40.         145.         320.33333333  56.33333333\n",
      " 106.33333333 115.         310.          93.         218.66666667\n",
      " 182.33333333 100.          86.33333333 186.         118.33333333\n",
      " 485.          48.33333333  71.66666667  66.66666667 123.33333333\n",
      " 104.66666667 190.         135.66666667 218.33333333 139.66666667\n",
      "  99.         123.33333333  98.66666667 260.         193.33333333\n",
      "  99.33333333 113.         115.33333333 110.         164.33333333\n",
      " 188.33333333 121.          46.33333333 401.33333333 129.\n",
      "  55.          87.66666667 128.33333333 116.         189.66666667]\n"
     ]
    }
   ],
   "source": [
    "numberCols = X_test.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numberCols.remove('id')\n",
    "\n",
    "X_train1 = X_train[0:1000][numberCols].to_numpy()\n",
    "X_test1 = X_test[0:1000][numberCols].to_numpy()\n",
    "y_train1 = y_train[0:1000].to_numpy()[:,0]\n",
    "y_test1 = y_test[0:1000].to_numpy()[:,0]\n",
    "\n",
    "knnr = KNNRegressor(n_neighbors = 3, metric = 'euclidean', mode = 'uniform')\n",
    "knnr.fit(X_train1, y_train1)\n",
    "res = knnr.predict(X_test1)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.1 (1 балл)</b>\n",
    "Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на [третьем семинаре](https://github.com/mmp-mmro-team/mmp_mmro_fall_2019/blob/master/lecture-notes/Sem03_knn.pdf). Не забудьте, что KNNRegressor должен уметь работать с этими функциями расстояния. Как вариант, можно реализовать метрики как [user-defined distance](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(x, z):\n",
    "    # Ваш код здесь\n",
    "    dist = 0\n",
    "    for i in range(len(x)):\n",
    "        if (x[i] != z[i]):\n",
    "            dist = 1\n",
    "            break\n",
    "    return dist\n",
    "\n",
    "def flattened_overlap(x, z):\n",
    "    # Ваш код здесь\n",
    "    pass\n",
    "\n",
    "def log_overlap(x, z):\n",
    "    # Ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 73.66666667  99.33333333 121.33333333 111.          99.33333333\n",
      " 121.33333333 111.         121.33333333 122.         121.33333333\n",
      " 121.33333333  99.33333333 121.33333333 111.         121.33333333\n",
      " 111.          73.66666667 111.          99.33333333 122.\n",
      " 121.33333333 121.33333333  99.33333333 189.33333333 111.\n",
      "  99.33333333  99.33333333 121.33333333  99.33333333 106.\n",
      " 121.33333333  73.66666667 121.33333333 136.         111.\n",
      " 111.         111.         121.33333333 121.33333333  73.66666667\n",
      " 111.         121.33333333 111.          73.66666667 111.\n",
      "  73.66666667 111.         111.         121.33333333  73.66666667\n",
      " 121.33333333 121.33333333 121.33333333  73.66666667  73.66666667\n",
      " 111.          73.66666667 111.         111.         121.33333333\n",
      " 121.33333333 121.33333333 111.         121.33333333 121.33333333\n",
      "  99.33333333 121.33333333 111.          99.33333333  99.33333333\n",
      " 111.         111.         111.         121.33333333  99.33333333\n",
      "  99.33333333 111.         111.          73.66666667 121.33333333\n",
      " 111.          73.66666667  73.66666667 121.33333333 111.\n",
      " 121.33333333  99.33333333  99.33333333  99.33333333  73.66666667\n",
      " 121.33333333  73.66666667 111.         111.         111.\n",
      " 121.33333333 121.33333333 111.          99.33333333  73.66666667\n",
      "  99.33333333 121.33333333 111.         111.         111.\n",
      " 111.         121.33333333 111.         111.         111.\n",
      " 121.33333333 111.         111.         111.          99.33333333\n",
      " 111.         111.          73.66666667  99.33333333  73.66666667\n",
      " 121.33333333 121.33333333 121.33333333 121.33333333 111.\n",
      " 111.         121.33333333 121.33333333 111.         121.33333333\n",
      " 121.33333333 121.33333333  99.33333333 121.33333333 189.33333333\n",
      " 111.         111.          73.66666667 121.33333333 121.33333333\n",
      " 111.          99.33333333 111.         121.33333333 111.\n",
      " 111.          73.66666667  99.33333333  99.33333333  73.66666667\n",
      " 111.         121.33333333 111.         121.33333333 121.33333333\n",
      "  99.33333333 111.          73.66666667 121.33333333 121.33333333\n",
      "  73.66666667 121.33333333 111.         121.33333333 111.\n",
      "  73.66666667  99.33333333  73.66666667  99.33333333  73.66666667\n",
      "  73.66666667 111.         111.         121.33333333 121.33333333\n",
      " 121.33333333 111.         111.         121.33333333 121.33333333\n",
      " 111.          73.66666667  99.33333333 121.33333333 111.\n",
      " 121.33333333  99.33333333  73.66666667  99.33333333  73.66666667\n",
      " 121.33333333 111.         106.          99.33333333  99.33333333\n",
      " 111.         111.         121.33333333  73.66666667  73.66666667\n",
      "  99.33333333 121.33333333 121.33333333 121.33333333  73.66666667\n",
      " 111.         121.33333333  73.66666667  99.33333333 121.33333333\n",
      "  73.66666667 111.          73.66666667  80.33333333 111.\n",
      "  99.33333333 111.         121.33333333 121.33333333  73.66666667\n",
      " 111.         111.         111.         111.          99.33333333\n",
      " 106.         121.33333333  99.33333333 111.          73.66666667\n",
      " 111.         111.          99.33333333  73.66666667 111.\n",
      " 121.33333333 121.33333333  99.33333333 121.33333333 111.\n",
      " 111.         121.33333333 136.         121.33333333 121.33333333\n",
      " 111.          99.33333333 121.33333333 121.33333333  99.33333333\n",
      " 111.          99.33333333  73.66666667 136.          73.66666667\n",
      "  99.33333333 111.         121.33333333 121.33333333  99.33333333\n",
      "  73.66666667 111.         136.         121.33333333 111.\n",
      " 111.         121.33333333 121.33333333 121.33333333 121.33333333\n",
      "  73.66666667 121.33333333 111.         121.33333333 111.\n",
      "  73.66666667  99.33333333 121.33333333 121.33333333 111.\n",
      "  99.33333333 121.33333333  73.66666667 111.          73.66666667\n",
      "  99.33333333  99.33333333 136.          73.66666667  73.66666667\n",
      " 111.          99.33333333 121.33333333 111.          99.33333333\n",
      " 111.         121.33333333 136.         106.         121.33333333\n",
      "  99.33333333 121.33333333  99.33333333  99.33333333 111.\n",
      " 111.         111.          73.66666667  99.33333333 111.\n",
      "  99.33333333 121.33333333 121.33333333  99.33333333  73.66666667\n",
      " 111.          99.33333333 121.33333333 111.         121.33333333\n",
      " 106.         111.          73.66666667 121.33333333  99.33333333\n",
      "  73.66666667 111.          99.33333333  73.66666667 121.33333333\n",
      " 189.33333333 121.33333333  73.66666667 121.33333333 136.\n",
      "  99.33333333  73.66666667 111.         121.33333333 121.33333333\n",
      "  73.66666667  73.66666667 111.         111.         189.33333333\n",
      " 111.         121.33333333 121.33333333  99.33333333  73.66666667\n",
      " 121.33333333  99.33333333 121.33333333 121.33333333 121.33333333\n",
      "  73.66666667 111.          68.66666667 111.         111.\n",
      "  99.33333333 121.33333333  73.66666667 111.         111.\n",
      "  99.33333333 111.          99.33333333  73.66666667  73.66666667\n",
      "  73.66666667  73.66666667 111.          99.33333333 111.\n",
      " 121.33333333 121.33333333  73.66666667  99.33333333  99.33333333\n",
      "  73.66666667 106.          73.66666667 106.         111.\n",
      " 111.          73.66666667 121.33333333 121.33333333  73.66666667\n",
      " 106.         111.         121.33333333 136.         121.33333333\n",
      " 121.33333333  68.66666667 121.33333333 121.33333333  99.33333333\n",
      " 111.          73.66666667  68.66666667 121.33333333 111.\n",
      "  73.66666667 121.33333333 189.33333333  99.33333333  80.33333333\n",
      "  99.33333333  99.33333333 111.         121.33333333  73.66666667\n",
      "  73.66666667  99.33333333 121.33333333 122.          73.66666667\n",
      " 121.33333333  99.33333333  99.33333333 121.33333333  99.33333333\n",
      "  73.66666667  99.33333333 111.         121.33333333 111.\n",
      " 121.33333333 121.33333333  73.66666667  99.33333333 111.\n",
      "  73.66666667 111.         111.         111.          99.33333333\n",
      "  99.33333333 121.33333333 121.33333333  99.33333333 111.\n",
      "  99.33333333 121.33333333 121.33333333  99.33333333 111.\n",
      " 111.          73.66666667 111.          73.66666667 121.33333333\n",
      " 136.         121.33333333 111.          99.33333333  80.33333333\n",
      " 111.         121.33333333 121.33333333  99.33333333  73.66666667\n",
      " 121.33333333  73.66666667 122.          73.66666667 111.\n",
      " 121.33333333 111.         121.33333333 111.         121.33333333\n",
      " 111.         121.33333333 121.33333333  73.66666667 111.\n",
      " 121.33333333 122.          73.66666667 111.         111.\n",
      " 121.33333333 111.          99.33333333 121.33333333 121.33333333\n",
      " 189.33333333 121.33333333 111.          99.33333333 121.33333333\n",
      "  99.33333333  99.33333333 121.33333333  99.33333333  73.66666667\n",
      "  99.33333333 121.33333333 121.33333333  73.66666667  99.33333333\n",
      " 121.33333333  80.33333333  99.33333333  99.33333333 111.\n",
      " 111.         121.33333333 121.33333333 111.         111.\n",
      " 111.         121.33333333  99.33333333 121.33333333 111.\n",
      " 111.         121.33333333 121.33333333 136.          99.33333333\n",
      " 121.33333333 111.          73.66666667 121.33333333 121.33333333\n",
      " 111.          99.33333333 111.         111.         121.33333333\n",
      " 121.33333333 121.33333333  99.33333333  73.66666667  73.66666667\n",
      "  73.66666667 121.33333333 121.33333333 111.          73.66666667\n",
      " 121.33333333  99.33333333 121.33333333  99.33333333  99.33333333\n",
      " 106.          99.33333333 111.          73.66666667 189.33333333\n",
      " 111.         121.33333333 111.          99.33333333 111.\n",
      " 121.33333333 121.33333333 121.33333333 121.33333333 136.\n",
      " 121.33333333 111.          73.66666667 121.33333333 121.33333333\n",
      "  99.33333333  99.33333333 121.33333333  99.33333333  73.66666667\n",
      " 121.33333333  73.66666667 121.33333333  99.33333333  99.33333333\n",
      "  73.66666667  73.66666667 111.          99.33333333 121.33333333\n",
      "  99.33333333 121.33333333  73.66666667 111.         121.33333333\n",
      " 121.33333333  73.66666667 111.          73.66666667  99.33333333\n",
      "  73.66666667  99.33333333 111.         111.         111.\n",
      " 121.33333333 121.33333333  73.66666667 121.33333333 121.33333333\n",
      " 111.         121.33333333 111.          73.66666667 111.\n",
      " 136.         111.          73.66666667 111.         121.33333333\n",
      " 111.          99.33333333  73.66666667  68.66666667 121.33333333\n",
      " 121.33333333 121.33333333  73.66666667  99.33333333 111.\n",
      " 121.33333333  99.33333333 121.33333333 111.         121.33333333\n",
      " 121.33333333 121.33333333 121.33333333 121.33333333 121.33333333\n",
      " 121.33333333  73.66666667 121.33333333  73.66666667 111.\n",
      " 111.         121.33333333  73.66666667 111.          73.66666667\n",
      " 111.         121.33333333 121.33333333  99.33333333 111.\n",
      " 111.         111.         121.33333333  99.33333333 111.\n",
      " 111.          73.66666667  73.66666667 106.         121.33333333\n",
      " 111.          80.33333333 111.         121.33333333 121.33333333\n",
      "  68.66666667  99.33333333  73.66666667 111.         121.33333333\n",
      "  99.33333333  73.66666667  99.33333333  99.33333333 121.33333333\n",
      " 121.33333333 111.         106.         122.         111.\n",
      "  68.66666667  73.66666667  73.66666667 121.33333333 111.\n",
      " 121.33333333  99.33333333  99.33333333 111.          99.33333333\n",
      "  99.33333333  73.66666667  73.66666667 121.33333333 111.\n",
      " 121.33333333  99.33333333  99.33333333 111.         121.33333333\n",
      " 121.33333333 111.          73.66666667 111.         121.33333333\n",
      "  73.66666667 111.          99.33333333 121.33333333 111.\n",
      " 121.33333333  73.66666667  99.33333333 121.33333333 189.33333333\n",
      "  99.33333333 111.         111.         121.33333333 121.33333333\n",
      " 121.33333333  80.33333333 121.33333333 111.         121.33333333\n",
      " 121.33333333 121.33333333 121.33333333 111.         111.\n",
      " 111.         121.33333333 111.         121.33333333  73.66666667\n",
      " 122.         121.33333333 111.         106.         121.33333333\n",
      "  73.66666667 121.33333333 121.33333333 111.          73.66666667\n",
      " 121.33333333  73.66666667 111.         121.33333333  73.66666667\n",
      " 122.          73.66666667 121.33333333 111.         111.\n",
      " 111.         121.33333333 121.33333333 111.         111.\n",
      "  99.33333333 121.33333333  99.33333333 111.          99.33333333\n",
      "  99.33333333 111.          99.33333333 111.         121.33333333\n",
      "  99.33333333 111.         111.          99.33333333 121.33333333\n",
      " 111.         111.          99.33333333 121.33333333  99.33333333\n",
      " 121.33333333  99.33333333 121.33333333 121.33333333  73.66666667\n",
      "  73.66666667 121.33333333  73.66666667  99.33333333  99.33333333\n",
      " 121.33333333 111.         121.33333333  73.66666667 111.\n",
      " 121.33333333 111.          99.33333333 121.33333333 121.33333333\n",
      " 111.          73.66666667 121.33333333  73.66666667 111.\n",
      "  73.66666667 121.33333333  73.66666667  99.33333333  73.66666667\n",
      " 189.33333333  73.66666667  99.33333333 121.33333333 121.33333333\n",
      " 121.33333333  73.66666667 121.33333333  99.33333333  73.66666667\n",
      "  73.66666667 189.33333333  73.66666667 111.          99.33333333\n",
      "  99.33333333 121.33333333  99.33333333 111.          99.33333333\n",
      " 121.33333333 121.33333333 111.         111.         111.\n",
      "  73.66666667 111.          99.33333333  99.33333333 111.\n",
      " 121.33333333  73.66666667  73.66666667 121.33333333 111.\n",
      " 121.33333333 121.33333333 111.          73.66666667 111.\n",
      " 111.         121.33333333 121.33333333  73.66666667 111.\n",
      " 121.33333333 121.33333333 111.         111.          73.66666667\n",
      "  73.66666667  73.66666667  99.33333333  99.33333333 121.33333333\n",
      " 121.33333333  73.66666667  80.33333333 111.         111.\n",
      " 111.         121.33333333  73.66666667 111.         121.33333333\n",
      " 121.33333333  99.33333333  99.33333333  99.33333333  99.33333333\n",
      " 111.         121.33333333 121.33333333  99.33333333  99.33333333\n",
      " 111.         121.33333333 111.          73.66666667 121.33333333\n",
      "  99.33333333 121.33333333  99.33333333 189.33333333 136.\n",
      " 111.          99.33333333  73.66666667 121.33333333 111.\n",
      " 111.         111.          73.66666667 121.33333333  99.33333333\n",
      " 121.33333333 111.         121.33333333  73.66666667 121.33333333\n",
      " 111.         121.33333333 111.          73.66666667  73.66666667\n",
      " 121.33333333 121.33333333 111.         111.         121.33333333\n",
      " 111.         189.33333333 121.33333333  99.33333333  99.33333333\n",
      "  99.33333333  73.66666667 111.         121.33333333  99.33333333\n",
      " 121.33333333  73.66666667  99.33333333 121.33333333  73.66666667\n",
      "  73.66666667 189.33333333  99.33333333  80.33333333  99.33333333\n",
      "  99.33333333 111.          99.33333333 122.          73.66666667\n",
      "  99.33333333 111.         111.         111.         111.\n",
      " 121.33333333  73.66666667 111.         121.33333333  73.66666667\n",
      "  99.33333333  73.66666667 122.         121.33333333 111.\n",
      " 121.33333333 111.         111.         121.33333333 111.\n",
      "  73.66666667 111.          99.33333333 111.         121.33333333\n",
      "  99.33333333 121.33333333 111.         121.33333333 111.\n",
      " 111.         111.         111.          99.33333333 111.\n",
      " 111.         121.33333333 121.33333333 121.33333333 121.33333333\n",
      "  99.33333333 111.          73.66666667 111.         121.33333333\n",
      " 121.33333333 121.33333333  73.66666667 121.33333333 121.33333333\n",
      "  99.33333333 111.          73.66666667  99.33333333 136.        ]\n"
     ]
    }
   ],
   "source": [
    "categoricalCols = X_test.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "X_train1 = X_train[0:1000][categoricalCols].to_numpy()\n",
    "X_test1 = X_test[0:1000][categoricalCols].to_numpy()\n",
    "y_train1 = y_train[0:1000].to_numpy()[:,0]\n",
    "y_test1 = y_test[0:1000].to_numpy()[:,0]\n",
    "\n",
    "\n",
    "knnr = KNNRegressor(n_neighbors = 3, metric = 'overlap', mode = 'distance')\n",
    "knnr.fit(X_train1, y_train1)\n",
    "res = knnr.predict(X_test1)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.2 (1 балл)</b> Найдите все категориальные признаки в данных. Подсчитайте для каждой из метрик качество на тестовой выборке `X_test` при числе соседей $k = 10$. Качество измеряйте с помощью RMSE.\n",
    "\n",
    "Какая функция расстояния оказалась лучшей? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'host_name',\n",
       " 'neighbourhood_group',\n",
       " 'neighbourhood',\n",
       " 'room_type',\n",
       " 'last_review']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "categoricalCols = numberCols = X_test.select_dtypes(include=[object]).columns.tolist()\n",
    "categoricalCols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.3 (1 балл) бонус</b> Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какого удалось достичь уровня качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.4 (2.5 балла)</b> Отойдем ненадолго от задачи регрессии и перейдём к задаче классификации: будем определять, являеться ли квартира дорогой $(target = 1)$ или дешевой $(target = 0)$. Будем считать дорогими квариры, цена которых выше среднего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['target'] = (data.price > data.price.mean()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте счетчики, которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, для каждого категориального признака $f_j(x)$ необходимо сделать следующее:\n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "\\begin{align}\n",
    "counts_j(c) = \\sum_{i=1}^l [f_j(x_i) = c]\n",
    "\\end{align}\n",
    "2. Число `successes` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "\\begin{align}\n",
    "successes_j(c) = \\sum_{i=1}^l[f_j(x_i) = c][y_i = +1].\n",
    "\\end{align}\n",
    "3. Сглаженное отношение двух предыдущих величин:\n",
    "\\begin{align}\n",
    "p_j(c) = \\frac{successes_j(c) + a}{counts_j(c) + b},\n",
    "\\end{align}\n",
    "\n",
    "где $a$ и $b$ - априорные счетчики (например, a = 1, b = 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counters(x):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        x: value on categorical feature for N objects\n",
    "    returns: vector of length N\n",
    "    \"\"\"\n",
    "    # Ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `successes` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанный по всей обучающей выборке. Реализуйте и такой вариант. Достаточно взять $n = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fold_counters(x):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        x: value on categorical feature for N objects\n",
    "    returns: vector of length N\n",
    "    \"\"\"\n",
    "    # Ваш код здесь\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.5 (1 балл)</b> Вернемся к задаче регрессии. Утверждается, что для задачи регрессии можно также сделать преобразование категориальных признаков в действительные числа. Для этого достаточно для каждого значения признака $f_j$ вычислить:\n",
    "\\begin{align}\n",
    "p_j(c) = g(T_i | f_j(x_i) = c),\n",
    "\\end{align}\n",
    "\n",
    "где $T_i$ - значения целевой переменной объекта $x_i$. Функция $g$ - среднее (mean) или среднеквадратичное отклонение (std).\n",
    "\n",
    "Закодируйте категориальные признаки обоими способами и найдите значение RMSE. Используйте евклидову метрику для поиска ближайших соседей. Для какой функции $g$ значение RMSE лучше? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Текстовые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.1 (2 балла)</b> Перейдем от категориальным признаков к текстовым. Рассмотрим 2 способа преобразования текста в действительные числа:\n",
    "- Мешок слов (Bag of Words)\n",
    "- TF-IDF\n",
    "\n",
    "[Здесь](https://scikit-learn.org/stable/modules/feature_extraction.html) вы можете прочитать про их применение в Питоне.\n",
    "\n",
    "Сравните оба способа на задаче регресси. Какую лучше метрику использовать: евклидову или косинусную меру? Постройте графики зависимости качества решения задачи от способа преобразования, метрики и количества соседей. Мера качества - RMSE.\n",
    "\n",
    "Объясните полученные результаты.\n",
    "\n",
    "Перед преобразованием не забудьте уменьшить размер словаря. Например, это можно сделать за счет приведения всех слов к одному регистру и удаления [стопслов](https://en.wikipedia.org/wiki/Stop_words) (артиклей, предлогов, союзов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.2 (1 балл)</b> Используя все доступные признаки, решите задачу регрессии. Для категориальных и текстовых признаков выберите лучшие преобразования. Повлияло ли добавление количественного признака на метрику качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4: Выводы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваши выводы здесь (ノ°∀°)ノ⌒･*:.｡. .｡.:*･゜ﾟ･*☆"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
